---
title: ""
author: ""
date: ""
output: 
  officedown::rdocx_document:
    #toc: true
    #toc_depth: 3
    fig_caption: true
    reference_docx: "template.docx"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = FALSE,
	message = T,
	warning = T
)
library(flextable)
library(tidyverse)
library(haven)
library(sf)
library(janitor)
library(officedown)
library(officer)
library(gtsummary)

```


\newpage



# Analyse de consistance des bases

## Importation et visualisation des 5 premières lignes de chaque base
```{r echo=FALSE}
# Importation de la base principale
Base_Principale <- read_dta("Donnees/Base_Principale.dta")
head(Base_Principale)
```

```{r echo=FALSE}
# Importation de la base MAD
Base_MAD <- read_dta("Donnees/Base_MAD.dta")
head(Base_MAD)
```

## Analyse de consistance des bases

### Analyse de consistance de la base principale
#### Détection des doublons
```{r}
# Créons une fonction qui va nous renvoyer le nombre de doublons et les doublons eux-mêmes
detect_doublons <- function(base) {
  # 1. Détection des doublons (lignes strictement identiques)
  doublons <- base %>%
    group_by(across(everything())) %>%
    filter(n() > 1) %>%
    ungroup()
  
  # 2. Nombre de doublons (vraies répétitions, sauf la 1re)
  nb_doublons <- sum(duplicated(base))
  
  # 3. Affichage
  cat("nombre de doublons :", nb_doublons, "\n\n")
  
  if (nrow(doublons) == 0) {
    cat("Aucun doublon trouvé.\n")
  } else {
    cat("Voici les lignes en doublon :\n")
    print(doublons)
  }
  
  # 4. Retourner les résultats
  return(invisible(list(nb = nb_doublons, lignes = doublons)))
}
```
```{r}
# Appliquons cette fonction à la base principale
detect_doublons(Base_Principale)
```

#### Comparaison hhsize et les autres variables donnant le nombre de personnes dans chaque classe d'âge
On va essayer de comparer la taille des méngages et la somme des individus dans le ménage selon les classes d'âge pour voir s'il y'a incohérence.
```{r}

observations_incoherentes <- Base_Principale %>%
  rowwise() %>%
  mutate(
    somme_classes_age = sum(c_across(HHSize05M:HHSize65AboveF), na.rm = TRUE),
    ecart = somme_classes_age - HHSize
  ) %>%
  ungroup() %>%
  filter(somme_classes_age > HHSize)

# Affichage
cat(" Nombre d'observations incohérentes :", nrow(observations_incoherentes), "\n")
print(observations_incoherentes)


```
Il y a `r nrow(observations_incoherentes)` d'observations incohérentes pour cela

### Analyse de consistance de la base MAD
L'analyse révèle les doublons suivants
```{r}
# Appliquons cette fonction à la base principale
detect_doublons(Base_MAD)
```

# Analyse des données et calcul des indicateurs
## Analyse socio-démographique des ménages
###  Caractéristiques générales des ménages
Le tableau ci-dessous présente quelques caractéristiques socio-économiques des ménages

```{r}
library(dplyr)
library(gtsummary)
library(labelled)  # pour to_factor()

# Sélection + conversion en facteurs avec labels
Base_Principale_labelled <- Base_Principale %>%
  select(HHSize, HHHAge, HHHSex, HHHEdu) %>%
  mutate(across(where(is.labelled), to_factor))  # Applique to_factor à toutes les variables 'labelled'

# Créer le tableau descriptif
Base_Principale_labelled %>%
  tbl_summary(
    by = HHHSex,  # Comparaison par sexe du chef de ménage
    statistic = list(
      all_continuous() ~ "{mean} (moy: {mean}, méd: {median})",
      all_categorical() ~ "{n} ({p}%)"
    ),
    digits = all_continuous() ~ 1,
    missing = "ifany"
  ) %>%
  add_overall() %>%
  add_n() %>%
  bold_labels()

```

Le tableau ci-dessus représente certaines caractéristiques socio-démographiques des ménages en général et en fonction du sexe du chef de ménage.

## Score de consommation alimentaire (SCA)

### Analyse descriptive des variables composant le SCA
```{r}


# Sélection des 8 variables qui composent le score SCA
sca_jours <- Base_Principale %>%
  select(FCSStap, FCSPulse, FCSDairy, FCSPr, FCSVeg, FCSFruit, FCSFat, FCSSugar)

# Analyse descriptive avec les labels automatiquement utilisés
tbl_summary_sca <- sca_jours %>%
  tbl_summary(
    statistic = list(all_continuous() ~ "{mean} ± {sd}"),
    digits = all_continuous() ~ 1,
    missing = "ifany"
  ) %>%
  bold_labels()

tbl_summary_sca


```

### Calcul du SCA
Le score de consommation alimentaire (SCA) ou Food Consumption Score (FCS) est un score composite pondéré calculé à partir des jours de consommation de certains groupes d'aliments, sur les 7 derniers jours, pondérés par leur valeur nutritionnelle.
Ce score a été calculé conformément à la méthodologie standardisée du Programme Alimentaire Mondial (PAM), en appliquant des poids nutritionnels spécifiques à huit groupes d'aliments, comme défini dans le guide technique du SCA : 2 pour les céréales, 3 pour les légumineuses, 4 pour les produits laitiers et les protéines animales, 1 pour les légumes et fruits, 0,5 pour les graisses et le sucre.
Formule de calcul :
\[
\text{FCS} = \sum (\text{fréquence de consommation} \times \text{poids nutritionnel})
\]

```{r}
Base_Principale <- Base_Principale %>%
  mutate(
    SCA =       2 * FCSStap +
                3 * FCSPulse +
                4 * FCSDairy +
                4 * FCSPr +
                1 * FCSVeg +
                1 * FCSFruit +
                0.5 * FCSFat +
                0.5 * FCSSugar
  ) %>%
  set_variable_labels(
    SCA = "Score de Consommation Alimentaire (SCA)"
  )

# Un petit gtsummary

Base_Principale %>%
  select(SCA) %>%
  tbl_summary(
    statistic = all_continuous() ~ "{mean} ± {sd} | Min: {min} | Max: {max}",
    digits = all_continuous() ~ 1,
    missing = "ifany"
  ) %>%
  bold_labels()


```

### Tableaux des poids
D'après le Programme alimentaire mondial , les poids sont répartis ainsi
| Groupe alimentaire           | Variable       | Poids |
|-----------------------------|----------------|-------|
| Céréales, tubercules        | `FCSStap`      | 2     |
| Légumineuses / noix         | `FCSPulse`     | 3     |
| Produits laitiers           | `FCSDairy`     | 4     |
| Viande, poisson, œufs       | `FCSPr`        | 4     |
| Légumes                     | `FCSVeg`       | 1     |
| Fruits                      | `FCSFruit`     | 1     |
| Huiles, graisses            | `FCSFat`       | 0.5   |
| Sucre et sucreries          | `FCSSugar`     | 0.5   |


### Categorisation du SCA selon les seuil 21/35 et 28/42 
```{r}
Base_Principale <- Base_Principale %>%
  mutate(
    SCA_cat_21_35 = case_when(
      SCA <= 21 ~ "Faible",
      SCA <= 35 ~ "Limite",
      TRUE ~ "Acceptable"
    ),
    SCA_cat_28_42 = case_when(
      SCA <= 28 ~ "Faible",
      SCA <= 42 ~ "Limite",
      TRUE ~ "Acceptable"
    )
  )

```

Visualisation des catégories

```{r}

# Table avec pourcentages
freq_21_35 <- Base_Principale %>%
  count(SCA_cat_21_35) %>%
  mutate(pct = round(100 * n / sum(n), 1))

# Barplot avec pourcentages affichés
ggplot(freq_21_35, aes(x = SCA_cat_21_35, y = n, fill = SCA_cat_21_35)) +
  geom_col() +
  geom_text(aes(label = paste0(pct, "%")), vjust = -0.5) +
  labs(
    title = "Catégorisation SCA (seuils 21/35)",
    x = "Catégorie",
    y = "Nombre de ménages"
  ) +
  scale_fill_brewer(palette = "Set2") +
  theme_minimal()


```

```{r}
freq_28_42 <- Base_Principale %>%
  count(SCA_cat_28_42) %>%
  mutate(pct = round(100 * n / sum(n), 1))

ggplot(freq_28_42, aes(x = SCA_cat_28_42, y = n, fill = SCA_cat_28_42)) +
  geom_col() +
  geom_text(aes(label = paste0(pct, "%")), vjust = -0.5) +
  labs(
    title = "Catégorisation SCA (seuils 28/42)",
    x = "Catégorie",
    y = "Nombre de ménages"
  ) +
  scale_fill_brewer(palette = "Set3") +
  theme_minimal()


```

### Représentation spatiale par région et par département du SCA et des catégories

Les shapefiles pour la représentation spatiale ont été trouvées dans le site HDX
```{r message=FALSE, warning=FALSE, include=FALSE}
library(sf)

# Exemple : lecture du shapefile (à adapter au chemin)
shp_tchad_region <- st_read("Donnees/shapefile_TCHAD/tcd_admbnda_adm1_20250212_AB.shp")
shp_tchad_dep <- st_read("Donnees/shapefile_TCHAD/tcd_admbnda_adm2_20250212_AB.shp")

```

#### Représentation spatiale par région du SCA et des catégories
On va pour cela agréger le SCA par région et fusionner la base avec le shapefile suivant la clé région
```{r}

# Agrégation du SCA par région création d'une nouvelle base
sca_region <- Base_Principale %>%
  group_by(ADMIN1Name) %>%
  summarise(
    SCA_moyen = mean(SCA, na.rm = TRUE),
    cat_21_35 = case_when(
      SCA_moyen <= 21 ~ "Faible",
      SCA_moyen <= 35 ~ "Limite",
      TRUE ~ "Acceptable"
    ),
    cat_28_46 = case_when(
      SCA_moyen <= 28 ~ "Faible",
      SCA_moyen <= 46 ~ "Limite",
      TRUE ~ "Acceptable"
    )
  )

```

Nettoyage des noms des clés avant la fusion
```{r}

# Nettoyage des noms côté données (Base_Principale)
base_clean <- sca_region %>%
  mutate(ADMIN1_clean = janitor::make_clean_names(ADMIN1Name))

# Nettoyage des noms côté shapefile
shp_clean <- shp_tchad_region %>%
  mutate(ADM1_FR_clean = janitor::make_clean_names(ADM1_FR))
# Fusion avec le shapefile selon le nom de région

shp_sca <- left_join(shp_clean, base_clean, 
                        by = c("ADM1_FR_clean" = "ADMIN1_clean"))

```

Carte du SCA

```{r fig.cap = "Score de Consommation Alimentaire (SCA) moyen par région"}

# 1. Polygones avec SCA moyen non NA (pour le fond et les étiquettes)
shp_sca_valid <- shp_sca %>%
  filter(!is.na(SCA_moyen))

# 2. Tracer la carte avec les bordures de toutes les régions
ggplot() +
  # a. Contours gris pâle de toutes les régions (même sans score)
  geom_sf(data = shp_sca, fill = NA, color = "grey80", size = 0.4) +
  
  # b. Couleur pour les régions avec score
  geom_sf(data = shp_sca_valid, aes(fill = SCA_moyen), color = "white", size = 0.5) +
  
  # c. Labels (région + score) uniquement pour celles avec données
  geom_sf_text(
    data = shp_sca_valid,
    aes(label = paste0(ADM1_FR, "\n(", round(SCA_moyen, 1), ")")),
    size = 1.3, fontface = "bold", check_overlap = TRUE
  ) +
  
  # Palette continue
  scale_fill_viridis_c(option = "C", direction = -1, na.value = "grey90") +
  
  # Mise en forme
  theme_minimal() +
  theme(
    legend.position = "right",
    plot.title = element_text(size = 14, face = "bold", hjust = 0.5),
    plot.subtitle = element_text(size = 11, hjust = 0.5)
  ) +
  labs(
    title = "Score de Consommation Alimentaire (SCA) moyen par région",
    subtitle = "Régions sans données visibles en contours uniquement",
    fill = "SCA moyen"
  )

```
Carte du SCA suivant les catégories

```{r}
 # pour mettre les cartes côte à côte

# --- Carte des catégories selon les seuils 21 / 35 ---
carte_cat_21_35 <- ggplot(shp_sca) +
  geom_sf(aes(fill = cat_21_35), color = "white", size = 0.4) +
  geom_sf_text(
    aes(label = paste0(ADM1_FR, "\n(", round(SCA_moyen, 1), ")")),
    size = 2, fontface = "bold", check_overlap = TRUE
  ) +
  scale_fill_brewer(palette = "Set2", na.value = "grey90") +
  theme_minimal() +
  labs(
    title = "SCA par région (Seuils 21/35)",
    fill = "Catégorie"
  )

# --- Carte des catégories selon les seuils 28 / 46 ---
carte_cat_28_46 <- ggplot(shp_sca) +
  geom_sf(aes(fill = cat_28_46), color = "white", size = 0.4) +
  geom_sf_text(
    aes(label = paste0(ADM1_FR, "\n(", round(SCA_moyen, 1), ")")),
    size = 1.5, fontface = "bold", check_overlap = TRUE
  ) +
  scale_fill_brewer(palette = "Set3", na.value = "grey90") +
  theme_minimal() +
  labs(
    title = "SCA par région(Seuils 28/46)",
    fill = "Catégorie"
  )

# --- Affichage côte à côte
print(carte_cat_21_35)
print(carte_cat_28_46)

```
#### Représentation spatiale par département du SCA et des catégories
```{r}
# Agrégation du SCA par région création d'une nouvelle base
sca_dep <- Base_Principale %>%
  group_by(ADMIN2Name) %>%
  summarise(
    SCA_moyen = mean(SCA, na.rm = TRUE),
    cat_21_35 = case_when(
      SCA_moyen <= 21 ~ "Faible",
      SCA_moyen <= 35 ~ "Limite",
      TRUE ~ "Acceptable"
    ),
    cat_28_46 = case_when(
      SCA_moyen <= 28 ~ "Faible",
      SCA_moyen <= 46 ~ "Limite",
      TRUE ~ "Acceptable"
    )
  )
```

```{r}
# Nettoyage des noms côté données (Base_Principale)
base_clean <- sca_dep %>%
  mutate(ADMIN2_clean = janitor::make_clean_names(ADMIN2Name))

# Nettoyage des noms côté shapefile
shp_clean <- shp_tchad_dep %>%
  mutate(ADM2_FR_clean = janitor::make_clean_names(ADM2_FR))
# Fusion avec le shapefile selon le nom de région

shp_sca <- left_join(shp_clean, base_clean, 
                        by = c("ADM2_FR_clean" = "ADMIN2_clean"))
```

```{r}
# 1. Polygones avec SCA moyen non NA (pour le fond et les étiquettes)
shp_sca_valid <- shp_sca %>%
  filter(!is.na(SCA_moyen))

# 2. Tracer la carte avec les bordures de toutes les régions
ggplot() +
  # a. Contours gris pâle de toutes les régions (même sans score)
  geom_sf(data = shp_sca, fill = NA, color = "grey80", size = 0.4) +
  
  # b. Couleur pour les régions avec score
  geom_sf(data = shp_sca_valid, aes(fill = SCA_moyen), color = "white", size = 0.5) +
  
  # c. Labels (région + score) uniquement pour celles avec données
  geom_sf_text(
    data = shp_sca_valid,
    aes(label = paste0(ADM2_FR, "\n(", round(SCA_moyen, 1), ")")),
    size = 1.5, fontface = "bold", check_overlap = TRUE
  ) +
  
  # Palette continue
  scale_fill_viridis_c(option = "C", direction = -1, na.value = "grey90") +
  
  # Mise en forme
  theme_minimal() +
  theme(
    legend.position = "right",
    plot.title = element_text(size = 14, face = "bold", hjust = 0.5),
    plot.subtitle = element_text(size = 11, hjust = 0.5)
  ) +
  labs(
    title = "Score de Consommation Alimentaire (SCA) moyen par département",
    subtitle = "Départements sans données visibles en contours uniquement",
    fill = "SCA moyen"
  )
```


## L’indice réduit des stratégies de survie (rCSI):
Le rCSI (reduced Coping Strategies Index) est un score composite pondéré mesurant les stratégies d'adaptation face à l'insécurité alimentaire au cours des 7 derniers jours.
Chaque stratégie a un poids reflétant sa gravité perçue.


### Analyse descriptive des variables composant le rCSI
```{r}

# Sélection des variables rCSI
rcsi_data <- Base_Principale %>%
  select(rCSILessQlty, rCSIBorrow, rCSIMealSize, rCSIMealAdult, rCSIMealNb)

# Analyse descriptive
rcsi_data %>%
  tbl_summary(
    statistic = all_continuous() ~ "{mean} ± {sd} | Min: {min}, Max: {max}",
    digits = all_continuous() ~ 1,
    missing = "ifany"
  ) %>%
  bold_labels()

```

### Calculer l’indice réduit des stratégies de survie
```{r}
Base_Principale <- Base_Principale %>%
  mutate(
    rCSI = 1 * rCSILessQlty +
           2 * rCSIBorrow +
           1 * rCSIMealSize +
           3 * rCSIMealAdult +
           1 * rCSIMealNb
  )

# Un petit gtsummary
Base_Principale %>%
  select(rCSI) %>%
  tbl_summary(
    statistic = all_continuous() ~ "{mean} ± {sd} | Min: {min}, Max: {max}",
    digits = all_continuous() ~ 1,
    missing = "ifany"
  ) %>%
  bold_labels()


```

### Tableaux des poids pour le rCSI
Les poids utilisés pour le calcul de l'indice réduit des stratégies de survie (rCSI) sont fournis par le Programme Alimentaire Mondial (PAM), et reflètent la gravité perçue des différentes stratégies de survie face à la pénurie alimentaire (PAM, 2021).


### Représentation spatiale par région et par département
#### Par région
```{r}
rCSI_region <- Base_Principale %>%
  group_by(ADMIN1Name) %>%
  summarise(
    rCSI_moyen = mean(rCSI, na.rm = TRUE))
```

Nettoyage des noms des clés avant la fusion
```{r}

# Nettoyage des noms côté données (Base_Principale)
base_clean <- rCSI_region %>%
  mutate(ADMIN1_clean = janitor::make_clean_names(ADMIN1Name))

# Nettoyage des noms côté shapefile
shp_clean <- shp_tchad_region %>%
  mutate(ADM1_FR_clean = janitor::make_clean_names(ADM1_FR))
# Fusion avec le shapefile selon le nom de région

shp_rCSI <- left_join(shp_clean, base_clean, 
                        by = c("ADM1_FR_clean" = "ADMIN1_clean"))

```

Carte du SCA

```{r fig.cap = "Indice réduit des stratégies de survie (rCSI) moyen par région"}

# 1. Polygones avec SCA moyen non NA (pour le fond et les étiquettes)
shp_rCSI_valid <- shp_rCSI %>%
  filter(!is.na(rCSI_moyen))

# 2. Tracer la carte avec les bordures de toutes les régions
ggplot() +
  # a. Contours gris pâle de toutes les régions (même sans score)
  geom_sf(data = shp_rCSI, fill = NA, color = "grey80", size = 0.4) +
  
  # b. Couleur pour les régions avec score
  geom_sf(data = shp_rCSI_valid, aes(fill = rCSI_moyen), color = "white", size = 0.5) +
  
  # c. Labels (région + score) uniquement pour celles avec données
  geom_sf_text(
    data = shp_rCSI_valid,
    aes(label = paste0(ADM1_FR, "\n(", round(rCSI_moyen, 1), ")")),
    size = 1.3, fontface = "bold", check_overlap = TRUE
  ) +
  
  # Palette continue
  scale_fill_viridis_c(option = "C", direction = -1, na.value = "grey90") +
  
  # Mise en forme
  theme_minimal() +
  theme(
    legend.position = "right",
    plot.title = element_text(size = 14, face = "bold", hjust = 0.5),
    plot.subtitle = element_text(size = 11, hjust = 0.5)
  ) +
  labs(
    title = "Indice réduit des stratégies de survie (rCSI) moyen par région",
    subtitle = "Régions sans données visibles en contours uniquement",
    fill = "SCA moyen"
  )

```


#### Par dépatement
```{r}
rCSI_dept <- Base_Principale %>%
  group_by(ADMIN2Name) %>%
  summarise(rCSI_moyen = mean(rCSI, na.rm = TRUE))

```

```{r}
# Nettoyage des noms côté données
dept_clean <- rCSI_dept %>%
  mutate(ADMIN2_clean = janitor::make_clean_names(ADMIN2Name))

# Nettoyage des noms côté shapefile
shp_dept_clean <- shp_tchad_dep %>%
  mutate(ADM2_FR_clean = janitor::make_clean_names(ADM2_FR))

shp_rCSI_dept <- left_join(shp_dept_clean, dept_clean,
                           by = c("ADM2_FR_clean" = "ADMIN2_clean"))


```

```{r}
# Filtrer uniquement les départements avec données
shp_rCSI_valid_dept <- shp_rCSI_dept %>%
  filter(!is.na(rCSI_moyen))

# Affichage de la carte
ggplot() +
  # Contours de tous les départements
  geom_sf(data = shp_rCSI_dept, fill = NA, color = "grey80", size = 0.4) +

  # Remplissage des départements avec score rCSI
  geom_sf(data = shp_rCSI_valid_dept, aes(fill = rCSI_moyen), color = "white", size = 0.4) +

  # Labels : nom du département + score
  geom_sf_text(
    data = shp_rCSI_valid_dept,
    aes(label = paste0(ADM2_FR, "\n(", round(rCSI_moyen, 1), ")")),
    size = 1.2, fontface = "bold", check_overlap = TRUE
  ) +

  # Palette continue
  scale_fill_viridis_c(option = "C", direction = -1, na.value = "grey90") +

  # Mise en page
  theme_minimal() +
  theme(
    legend.position = "right",
    plot.title = element_text(size = 13, face = "bold", hjust = 0.5),
    plot.subtitle = element_text(size = 10, hjust = 0.5)
  ) +
  labs(
    title = "Indice réduit des stratégies de survie (rCSI) moyen par département",
    subtitle = "Départements sans données visibles uniquement par les contours",
    fill = "rCSI moyen"
  )

```
## Stratégies d'adaptation aux moyens d'existence (LhCSI)
### Analyse descriptive des variables du LhCSI
```{r}


Base_Principale %>%
  mutate(across(
    c(
      LhCSIStress1, LhCSIStress2, LhCSIStress3, LhCSIStress4,
      LhCSICrisis1, LhCSICrisis2, LhCSICrisis3,
      LhCSIEmergency1, LhCSIEmergency2, LhCSIEmergency3
    ),
    ~ to_factor(.)))  %>% 
  select(
    # Stress
    LhCSIStress1, LhCSIStress2, LhCSIStress3, LhCSIStress4,
    # Crise
    LhCSICrisis1, LhCSICrisis2, LhCSICrisis3,
    # Urgence
    LhCSIEmergency1, LhCSIEmergency2, LhCSIEmergency3
  ) %>%
  tbl_summary(
    by = NULL,
    statistic = ~ "{n} ({p}%)",
    missing = "ifany"
  ) %>%
  bold_labels()

```

### Proportion de menage en situation de stress, de crise et d’urgence en 2022 et 2023
```{r}
Base_Principale <- Base_Principale %>%
  mutate(
    LhCSI_urgence = if_any(c(LhCSIEmergency1, LhCSIEmergency2, LhCSIEmergency3), ~ . == 3),
    LhCSI_crise   = if_any(c(LhCSICrisis1, LhCSICrisis2, LhCSICrisis3), ~ . == 3),
    LhCSI_stress  = if_any(c(LhCSIStress1, LhCSIStress2, LhCSIStress3, LhCSIStress4), ~ . == 3),

    LhCSI_severite = case_when(
      LhCSI_urgence ~ "Urgence",
      LhCSI_crise   ~ "Crise",
      LhCSI_stress  ~ "Stress",
      TRUE          ~ "Aucune stratégie"
    )
  )


```

```{r}
library(dplyr)
library(ggplot2)

# Filtrage des années 2022 et 2023
Base_Principale %>%
  filter(YEAR %in% c(2022, 2023)) %>%
  count(YEAR, LhCSI_severite) %>%
  group_by(YEAR) %>%
  mutate(Proportion = round(100 * n / sum(n), 1)) %>%
  ggplot(aes(x = LhCSI_severite, y = Proportion, fill = LhCSI_severite)) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.7), width = 0.6) +
  geom_text(aes(label = paste0(Proportion, "%")),
            position = position_dodge(width = 0.7), vjust = -0.5, size = 3.5) +
  facet_wrap(~YEAR) +
  scale_fill_brewer(palette = "Set2") +
  labs(
    title = "Répartition des ménages par niveau de sévérité (LhCSI)",
    subtitle = "Comparaison entre 2022 et 2023",
    x = "Niveau de sévérité",
    y = "Proportion (%)",
    fill = "Catégorie LhCSI"
  ) +
  theme_minimal() +
  theme(
    strip.text = element_text(size = 11, face = "bold"),
    plot.title = element_text(size = 14, face = "bold", hjust = 0.5),
    plot.subtitle = element_text(size = 11, hjust = 0.5)
  )


```

### Representation spatiale (region et departement) des strategies d’adaptation

#### Representation spatiale par region des strategies d’adaptation
Ici, on représntera les statégies d'adaptation dominante

```{r}
library(dplyr)

lhcsi_region <- Base_Principale %>%
  filter(!is.na(ADMIN1Name)) %>%
  group_by(ADMIN1Name) %>%
  count(LhCSI_severite) %>%
  slice_max(order_by = n, n = 1, with_ties = FALSE) %>%
  rename(severite_dominante = LhCSI_severite) %>%
  mutate(ADMIN1_clean = janitor::make_clean_names(ADMIN1Name))

```

```{r}
shp_region_clean <- shp_tchad_region %>%
  mutate(ADM1_FR_clean = janitor::make_clean_names(ADM1_FR))

shp_lhcsi_region <- left_join(shp_region_clean, lhcsi_region,
                              by = c("ADM1_FR_clean" = "ADMIN1_clean"))

```

```{r}
library(ggplot2)

ggplot(shp_lhcsi_region) +
  geom_sf(aes(fill = severite_dominante), color = "white", size = 0.4) +
  geom_sf_text(aes(label = ADM1_FR), size = 2.5, fontface = "bold", check_overlap = TRUE) +
  scale_fill_brewer(palette = "Set2", na.value = "grey90") +
  labs(
    title = "Stratégie d’adaptation dominante par région (LhCSI)",
    fill = "Niveau de sévérité"
  ) +
  theme_minimal()

```

#### Representation spatiale par département des strategies d’adaptation
```{r}
lhcsi_dept <- Base_Principale %>%
  filter(!is.na(ADMIN2Name)) %>%
  group_by(ADMIN2Name) %>%
  count(LhCSI_severite) %>%
  slice_max(order_by = n, n = 1, with_ties = FALSE) %>%
  rename(severite_dominante = LhCSI_severite) %>%
  mutate(ADMIN2_clean = janitor::make_clean_names(ADMIN2Name))

```

```{r}
shp_dept_clean <- shp_tchad_dep %>%
  mutate(ADM2_FR_clean = janitor::make_clean_names(ADM2_FR))

shp_lhcsi_dep <- left_join(shp_dept_clean, lhcsi_dept,
                            by = c("ADM2_FR_clean" = "ADMIN2_clean"))

```
```{r}
ggplot(shp_lhcsi_dep) +
  geom_sf(aes(fill = severite_dominante), color = "white", size = 0.4) +
  geom_sf_text(aes(label = ADM2_FR), size = 1.8, fontface = "bold", check_overlap = TRUE) +
  scale_fill_brewer(palette = "Set3", na.value = "grey90") +
  labs(
    title = "Stratégie d’adaptation dominante par département (LhCSI)",
    fill = "Niveau de sévérité"
  ) +
  theme_minimal()

```
## Score de diversité alimentaire des ménages

### Analyse descriptive des variables qui composent le SERS
```{r}
sers_vars <- c(
  "SERSRebondir", "SERSRevenue", "SERSMoyen", "SERSDifficultes",
  "SERSSurvivre", "SERSFamAmis", "SERSPoliticiens", "SERSLecons",
  "SERSPreparerFuture", "SERSAvertissementEven"
)

# Conversion des 10 variables en facteurs avec labels textuels
Base_Principale <- Base_Principale %>%
  mutate(across(all_of(sers_vars), to_factor))

Base_Principale %>%
  select(starts_with("SERS")) %>%
  tbl_summary(
    statistic = ~ "{n} ({p}%)",
    missing = "ifany"
  ) %>%
  bold_labels()

```

### Calcul du SERS et création des catégories

```{r}
# Calcul du score total et normalisation min-max entre 0 et 100
Base_Principale <- Base_Principale %>%
  rowwise() %>%
  mutate(
    across(all_of(sers_vars), ~ as.numeric(.)),
    SERS_total = sum(c_across(all_of(sers_vars)), na.rm = TRUE),
    SERS = (SERS_total - 10) / (50 - 10) * 100  # min = 10 (1*10), max = 50 (5*10)
  ) %>%
  ungroup()

# Création des catégories
Base_Principale <- Base_Principale %>%
  mutate(
    SERS_cat = case_when(
      SERS < 33 ~ "Faible",
      SERS >= 33 & SERS < 66 ~ "Moyen",
      SERS >= 66 ~ "Élevé",
      TRUE ~ NA_character_
    )
  )

```

### Représentation spatiale
#### Par région
```{r}
SERS_region <- Base_Principale %>%
  group_by(ADMIN1Name) %>%
  summarise(SERS_moyen = mean(SERS, na.rm = TRUE)) %>%
  mutate(
    SERS_cat_region = case_when(
      SERS_moyen < 33 ~ "Faible",
      SERS_moyen >= 33 & SERS_moyen < 66 ~ "Moyen",
      SERS_moyen >= 66 ~ "Élevé"
    ),
    ADMIN1_clean = janitor::make_clean_names(ADMIN1Name)
  )

```

```{r}
SERS_dept <- Base_Principale %>%
  group_by(ADMIN2Name) %>%
  summarise(SERS_moyen = mean(SERS, na.rm = TRUE)) %>%
  mutate(
    SERS_cat_dept = case_when(
      SERS_moyen < 33 ~ "Faible",
      SERS_moyen >= 33 & SERS_moyen < 66 ~ "Moyen",
      SERS_moyen >= 66 ~ "Élevé"
    ),
    ADMIN2_clean = janitor::make_clean_names(ADMIN2Name)
  )

```

```{r}
shp_region_clean <- shp_tchad_region %>%
  mutate(ADM1_FR_clean = janitor::make_clean_names(ADM1_FR))

shp_sers_region <- left_join(shp_region_clean, SERS_region,
                             by = c("ADM1_FR_clean" = "ADMIN1_clean"))

shp_sers_dept <- left_join(shp_dept_clean, SERS_dept,
                             by = c("ADM2_FR_clean" = "ADMIN2_clean"))

```

```{r}
ggplot(shp_sers_region) +
  geom_sf(aes(fill = SERS_moyen), color = "white") +
  geom_sf_text(aes(label = ADM1_FR), size = 2.5, fontface = "bold", check_overlap = TRUE) +
  scale_fill_viridis_c(option = "C", direction = -1, na.value = "grey90") +
  labs(
    title = "Score moyen de résilience (SERS) par région",
    subtitle = "SERS moyen (0 = faible résilience, 100 = très forte)",
    fill = "SERS moyen"
  ) +
  theme_minimal()

```

```{r}
ggplot(shp_sers_region) +
  geom_sf(aes(fill = SERS_cat_region), color = "white") +
  geom_sf_text(aes(label = ADM1_FR), size = 2.5, fontface = "bold", check_overlap = TRUE) +
  scale_fill_brewer(palette = "YlGnBu", na.value = "grey90") +
  labs(
    title = "Catégorie de résilience (SERS) par région",
    subtitle = "Faible : <33 | Moyen : [33–66) | Élevé : ≥66",
    fill = "Catégorie SERS"
  ) +
  theme_minimal()

```


```{r}
ggplot(shp_sers_dept) +
  geom_sf(aes(fill = SERS_moyen), color = "white") +
  geom_sf_text(aes(label = ADM2_FR), size = 1.8, fontface = "bold", check_overlap = TRUE) +
  scale_fill_viridis_c(option = "C", direction = -1, na.value = "grey90") +
  labs(
    title = "Score moyen de résilience (SERS) par département",
    subtitle = "SERS de 0 (très faible) à 100 (très élevé)",
    fill = "SERS moyen"
  ) +
  theme_minimal()

```

```{r}
ggplot(shp_sers_dept) +
  geom_sf(aes(fill = SERS_cat_dept), color = "white") +
  geom_sf_text(aes(label = ADM2_FR), size = 1.6, fontface = "bold", check_overlap = TRUE) +
  scale_fill_brewer(palette = "YlGnBu", na.value = "grey90") +
  labs(
    title = "Catégorie de résilience (SERS) par département",
    subtitle = "Faible : <33 | Moyen : [33–66) | Élevé : ≥66",
    fill = "Catégorie SERS"
  ) +
  theme_minimal()

```

























# Analyse des données et calcul des indicateurs
## Analyse socio-démographique des ménages
###  Caractéristiques générales des ménages
Le tableau ci-dessous présente quelques caractéristiques socio-économiques des ménages

```{r}
library(dplyr)
library(gtsummary)
library(labelled)  # pour to_factor()

# Sélection + conversion en facteurs avec labels
Base_Principale_labelled <- Base_Principale %>%
  select(HHSize, HHHAge, HHHSex, HHHEdu) %>%
  mutate(across(where(is.labelled), to_factor))  # Applique to_factor à toutes les variables 'labelled'

# Créer le tableau descriptif
Base_Principale_labelled %>%
  tbl_summary(
    by = HHHSex,  # Comparaison par sexe du chef de ménage
    statistic = list(
      all_continuous() ~ "{mean} (moy: {mean}, méd: {median})",
      all_categorical() ~ "{n} ({p}%)"
    ),
    digits = all_continuous() ~ 1,
    missing = "ifany"
  ) %>%
  add_overall() %>%
  add_n() %>%
  bold_labels()

```

Le tableau ci-dessus représente certaines caractéristiques socio-démographiques des ménages en général et en fonction du sexe du chef de ménage.

## Score de consommation alimentaire (SCA)

### Analyse descriptive des variables composant le SCA
```{r}


# Sélection des 8 variables qui composent le score SCA
sca_jours <- Base_Principale %>%
  select(FCSStap, FCSPulse, FCSDairy, FCSPr, FCSVeg, FCSFruit, FCSFat, FCSSugar)

# Analyse descriptive avec les labels automatiquement utilisés
tbl_summary_sca <- sca_jours %>%
  tbl_summary(
    statistic = list(all_continuous() ~ "{mean} ± {sd}"),
    digits = all_continuous() ~ 1,
    missing = "ifany"
  ) %>%
  bold_labels()

tbl_summary_sca


```

### Calcul du SCA
Le score de consommation alimentaire (SCA) ou Food Consumption Score (FCS) est un score composite pondéré calculé à partir des jours de consommation de certains groupes d'aliments, sur les 7 derniers jours, pondérés par leur valeur nutritionnelle.
Ce score a été calculé conformément à la méthodologie standardisée du Programme Alimentaire Mondial (PAM), en appliquant des poids nutritionnels spécifiques à huit groupes d'aliments, comme défini dans le guide technique du SCA : 2 pour les céréales, 3 pour les légumineuses, 4 pour les produits laitiers et les protéines animales, 1 pour les légumes et fruits, 0,5 pour les graisses et le sucre.
Formule de calcul :
\[
\text{FCS} = \sum (\text{fréquence de consommation} \times \text{poids nutritionnel})
\]

```{r}
Base_Principale <- Base_Principale %>%
  mutate(
    SCA =       2 * FCSStap +
                3 * FCSPulse +
                4 * FCSDairy +
                4 * FCSPr +
                1 * FCSVeg +
                1 * FCSFruit +
                0.5 * FCSFat +
                0.5 * FCSSugar
  ) %>%
  set_variable_labels(
    SCA = "Score de Consommation Alimentaire (SCA)"
  )

# Un petit gtsummary

Base_Principale %>%
  select(SCA) %>%
  tbl_summary(
    statistic = all_continuous() ~ "{mean} ± {sd} | Min: {min} | Max: {max}",
    digits = all_continuous() ~ 1,
    missing = "ifany"
  ) %>%
  bold_labels()


```

### Tableaux des poids
D'après le Programme alimentaire mondial , les poids sont répartis ainsi
| Groupe alimentaire           | Variable       | Poids |
|-----------------------------|----------------|-------|
| Céréales, tubercules        | `FCSStap`      | 2     |
| Légumineuses / noix         | `FCSPulse`     | 3     |
| Produits laitiers           | `FCSDairy`     | 4     |
| Viande, poisson, œufs       | `FCSPr`        | 4     |
| Légumes                     | `FCSVeg`       | 1     |
| Fruits                      | `FCSFruit`     | 1     |
| Huiles, graisses            | `FCSFat`       | 0.5   |
| Sucre et sucreries          | `FCSSugar`     | 0.5   |


### Categorisation du SCA selon les seuil 21/35 et 28/42 
```{r}
Base_Principale <- Base_Principale %>%
  mutate(
    SCA_cat_21_35 = case_when(
      SCA <= 21 ~ "Faible",
      SCA <= 35 ~ "Limite",
      TRUE ~ "Acceptable"
    ),
    SCA_cat_28_42 = case_when(
      SCA <= 28 ~ "Faible",
      SCA <= 42 ~ "Limite",
      TRUE ~ "Acceptable"
    )
  )

```

Visualisation des catégories

```{r}

# Table avec pourcentages
freq_21_35 <- Base_Principale %>%
  count(SCA_cat_21_35) %>%
  mutate(pct = round(100 * n / sum(n), 1))

# Barplot avec pourcentages affichés
ggplot(freq_21_35, aes(x = SCA_cat_21_35, y = n, fill = SCA_cat_21_35)) +
  geom_col() +
  geom_text(aes(label = paste0(pct, "%")), vjust = -0.5) +
  labs(
    title = "Catégorisation SCA (seuils 21/35)",
    x = "Catégorie",
    y = "Nombre de ménages"
  ) +
  scale_fill_brewer(palette = "Set2") +
  theme_minimal()


```

```{r}
freq_28_42 <- Base_Principale %>%
  count(SCA_cat_28_42) %>%
  mutate(pct = round(100 * n / sum(n), 1))

ggplot(freq_28_42, aes(x = SCA_cat_28_42, y = n, fill = SCA_cat_28_42)) +
  geom_col() +
  geom_text(aes(label = paste0(pct, "%")), vjust = -0.5) +
  labs(
    title = "Catégorisation SCA (seuils 28/42)",
    x = "Catégorie",
    y = "Nombre de ménages"
  ) +
  scale_fill_brewer(palette = "Set3") +
  theme_minimal()


```

### Représentation spatiale par région et par département du SCA et des catégories

Les shapefiles pour la représentation spatiale ont été trouvées dans le site HDX
```{r message=FALSE, warning=FALSE, include=FALSE}
library(sf)

# Exemple : lecture du shapefile (à adapter au chemin)
shp_tchad_region <- st_read("Donnees/shapefile_TCHAD/tcd_admbnda_adm1_20250212_AB.shp")
shp_tchad_dep <- st_read("Donnees/shapefile_TCHAD/tcd_admbnda_adm2_20250212_AB.shp")

```

#### Représentation spatiale par région du SCA et des catégories
On va pour cela agréger le SCA par région et fusionner la base avec le shapefile suivant la clé région
```{r}

# Agrégation du SCA par région création d'une nouvelle base
sca_region <- Base_Principale %>%
  group_by(ADMIN1Name) %>%
  summarise(
    SCA_moyen = mean(SCA, na.rm = TRUE),
    cat_21_35 = case_when(
      SCA_moyen <= 21 ~ "Faible",
      SCA_moyen <= 35 ~ "Limite",
      TRUE ~ "Acceptable"
    ),
    cat_28_46 = case_when(
      SCA_moyen <= 28 ~ "Faible",
      SCA_moyen <= 46 ~ "Limite",
      TRUE ~ "Acceptable"
    )
  )

```

Nettoyage des noms des clés avant la fusion
```{r}

# Nettoyage des noms côté données (Base_Principale)
base_clean <- sca_region %>%
  mutate(ADMIN1_clean = janitor::make_clean_names(ADMIN1Name))

# Nettoyage des noms côté shapefile
shp_clean <- shp_tchad_region %>%
  mutate(ADM1_FR_clean = janitor::make_clean_names(ADM1_FR))
# Fusion avec le shapefile selon le nom de région

shp_sca <- left_join(shp_clean, base_clean, 
                        by = c("ADM1_FR_clean" = "ADMIN1_clean"))

```

Carte du SCA

```{r fig.cap = "Score de Consommation Alimentaire (SCA) moyen par région"}

# 1. Polygones avec SCA moyen non NA (pour le fond et les étiquettes)
shp_sca_valid <- shp_sca %>%
  filter(!is.na(SCA_moyen))

# 2. Tracer la carte avec les bordures de toutes les régions
ggplot() +
  # a. Contours gris pâle de toutes les régions (même sans score)
  geom_sf(data = shp_sca, fill = NA, color = "grey80", size = 0.4) +
  
  # b. Couleur pour les régions avec score
  geom_sf(data = shp_sca_valid, aes(fill = SCA_moyen), color = "white", size = 0.5) +
  
  # c. Labels (région + score) uniquement pour celles avec données
  geom_sf_text(
    data = shp_sca_valid,
    aes(label = paste0(ADM1_FR, "\n(", round(SCA_moyen, 1), ")")),
    size = 1.3, fontface = "bold", check_overlap = TRUE
  ) +
  
  # Palette continue
  scale_fill_viridis_c(option = "C", direction = -1, na.value = "grey90") +
  
  # Mise en forme
  theme_minimal() +
  theme(
    legend.position = "right",
    plot.title = element_text(size = 14, face = "bold", hjust = 0.5),
    plot.subtitle = element_text(size = 11, hjust = 0.5)
  ) +
  labs(
    title = "Score de Consommation Alimentaire (SCA) moyen par région",
    subtitle = "Régions sans données visibles en contours uniquement",
    fill = "SCA moyen"
  )

```
Carte du SCA suivant les catégories

```{r}
 # pour mettre les cartes côte à côte

# --- Carte des catégories selon les seuils 21 / 35 ---
carte_cat_21_35 <- ggplot(shp_sca) +
  geom_sf(aes(fill = cat_21_35), color = "white", size = 0.4) +
  geom_sf_text(
    aes(label = paste0(ADM1_FR, "\n(", round(SCA_moyen, 1), ")")),
    size = 2, fontface = "bold", check_overlap = TRUE
  ) +
  scale_fill_brewer(palette = "Set2", na.value = "grey90") +
  theme_minimal() +
  labs(
    title = "SCA par région (Seuils 21/35)",
    fill = "Catégorie"
  )

# --- Carte des catégories selon les seuils 28 / 46 ---
carte_cat_28_46 <- ggplot(shp_sca) +
  geom_sf(aes(fill = cat_28_46), color = "white", size = 0.4) +
  geom_sf_text(
    aes(label = paste0(ADM1_FR, "\n(", round(SCA_moyen, 1), ")")),
    size = 1.5, fontface = "bold", check_overlap = TRUE
  ) +
  scale_fill_brewer(palette = "Set3", na.value = "grey90") +
  theme_minimal() +
  labs(
    title = "SCA par région(Seuils 28/46)",
    fill = "Catégorie"
  )

# --- Affichage côte à côte
print(carte_cat_21_35)
print(carte_cat_28_46)

```
#### Représentation spatiale par département du SCA et des catégories
```{r}
# Agrégation du SCA par région création d'une nouvelle base
sca_dep <- Base_Principale %>%
  group_by(ADMIN2Name) %>%
  summarise(
    SCA_moyen = mean(SCA, na.rm = TRUE),
    cat_21_35 = case_when(
      SCA_moyen <= 21 ~ "Faible",
      SCA_moyen <= 35 ~ "Limite",
      TRUE ~ "Acceptable"
    ),
    cat_28_46 = case_when(
      SCA_moyen <= 28 ~ "Faible",
      SCA_moyen <= 46 ~ "Limite",
      TRUE ~ "Acceptable"
    )
  )
```

```{r}
# Nettoyage des noms côté données (Base_Principale)
base_clean <- sca_dep %>%
  mutate(ADMIN2_clean = janitor::make_clean_names(ADMIN2Name))

# Nettoyage des noms côté shapefile
shp_clean <- shp_tchad_dep %>%
  mutate(ADM2_FR_clean = janitor::make_clean_names(ADM2_FR))
# Fusion avec le shapefile selon le nom de région

shp_sca <- left_join(shp_clean, base_clean, 
                        by = c("ADM2_FR_clean" = "ADMIN2_clean"))
```

```{r}
# 1. Polygones avec SCA moyen non NA (pour le fond et les étiquettes)
shp_sca_valid <- shp_sca %>%
  filter(!is.na(SCA_moyen))

# 2. Tracer la carte avec les bordures de toutes les régions
ggplot() +
  # a. Contours gris pâle de toutes les régions (même sans score)
  geom_sf(data = shp_sca, fill = NA, color = "grey80", size = 0.4) +
  
  # b. Couleur pour les régions avec score
  geom_sf(data = shp_sca_valid, aes(fill = SCA_moyen), color = "white", size = 0.5) +
  
  # c. Labels (région + score) uniquement pour celles avec données
  geom_sf_text(
    data = shp_sca_valid,
    aes(label = paste0(ADM2_FR, "\n(", round(SCA_moyen, 1), ")")),
    size = 1.5, fontface = "bold", check_overlap = TRUE
  ) +
  
  # Palette continue
  scale_fill_viridis_c(option = "C", direction = -1, na.value = "grey90") +
  
  # Mise en forme
  theme_minimal() +
  theme(
    legend.position = "right",
    plot.title = element_text(size = 14, face = "bold", hjust = 0.5),
    plot.subtitle = element_text(size = 11, hjust = 0.5)
  ) +
  labs(
    title = "Score de Consommation Alimentaire (SCA) moyen par département",
    subtitle = "Départements sans données visibles en contours uniquement",
    fill = "SCA moyen"
  )
```


## L’indice réduit des stratégies de survie (rCSI):
Le rCSI (reduced Coping Strategies Index) est un score composite pondéré mesurant les stratégies d'adaptation face à l'insécurité alimentaire au cours des 7 derniers jours.
Chaque stratégie a un poids reflétant sa gravité perçue.


### Analyse descriptive des variables composant le rCSI
```{r}

# Sélection des variables rCSI
rcsi_data <- Base_Principale %>%
  select(rCSILessQlty, rCSIBorrow, rCSIMealSize, rCSIMealAdult, rCSIMealNb)

# Analyse descriptive
rcsi_data %>%
  tbl_summary(
    statistic = all_continuous() ~ "{mean} ± {sd} | Min: {min}, Max: {max}",
    digits = all_continuous() ~ 1,
    missing = "ifany"
  ) %>%
  bold_labels()

```

### Calculer l’indice réduit des stratégies de survie
```{r}
Base_Principale <- Base_Principale %>%
  mutate(
    rCSI = 1 * rCSILessQlty +
           2 * rCSIBorrow +
           1 * rCSIMealSize +
           3 * rCSIMealAdult +
           1 * rCSIMealNb
  )

# Un petit gtsummary
Base_Principale %>%
  select(rCSI) %>%
  tbl_summary(
    statistic = all_continuous() ~ "{mean} ± {sd} | Min: {min}, Max: {max}",
    digits = all_continuous() ~ 1,
    missing = "ifany"
  ) %>%
  bold_labels()


```

### Tableaux des poids pour le rCSI
Les poids utilisés pour le calcul de l'indice réduit des stratégies de survie (rCSI) sont fournis par le Programme Alimentaire Mondial (PAM), et reflètent la gravité perçue des différentes stratégies de survie face à la pénurie alimentaire (PAM, 2021).


### Représentation spatiale par région et par département
#### Par région
```{r}
rCSI_region <- Base_Principale %>%
  group_by(ADMIN1Name) %>%
  summarise(
    rCSI_moyen = mean(rCSI, na.rm = TRUE))
```

Nettoyage des noms des clés avant la fusion
```{r}

# Nettoyage des noms côté données (Base_Principale)
base_clean <- rCSI_region %>%
  mutate(ADMIN1_clean = janitor::make_clean_names(ADMIN1Name))

# Nettoyage des noms côté shapefile
shp_clean <- shp_tchad_region %>%
  mutate(ADM1_FR_clean = janitor::make_clean_names(ADM1_FR))
# Fusion avec le shapefile selon le nom de région

shp_rCSI <- left_join(shp_clean, base_clean, 
                        by = c("ADM1_FR_clean" = "ADMIN1_clean"))

```

Carte du SCA

```{r fig.cap = "Indice réduit des stratégies de survie (rCSI) moyen par région"}

# 1. Polygones avec SCA moyen non NA (pour le fond et les étiquettes)
shp_rCSI_valid <- shp_rCSI %>%
  filter(!is.na(rCSI_moyen))

# 2. Tracer la carte avec les bordures de toutes les régions
ggplot() +
  # a. Contours gris pâle de toutes les régions (même sans score)
  geom_sf(data = shp_rCSI, fill = NA, color = "grey80", size = 0.4) +
  
  # b. Couleur pour les régions avec score
  geom_sf(data = shp_rCSI_valid, aes(fill = rCSI_moyen), color = "white", size = 0.5) +
  
  # c. Labels (région + score) uniquement pour celles avec données
  geom_sf_text(
    data = shp_rCSI_valid,
    aes(label = paste0(ADM1_FR, "\n(", round(rCSI_moyen, 1), ")")),
    size = 1.3, fontface = "bold", check_overlap = TRUE
  ) +
  
  # Palette continue
  scale_fill_viridis_c(option = "C", direction = -1, na.value = "grey90") +
  
  # Mise en forme
  theme_minimal() +
  theme(
    legend.position = "right",
    plot.title = element_text(size = 14, face = "bold", hjust = 0.5),
    plot.subtitle = element_text(size = 11, hjust = 0.5)
  ) +
  labs(
    title = "Indice réduit des stratégies de survie (rCSI) moyen par région",
    subtitle = "Régions sans données visibles en contours uniquement",
    fill = "SCA moyen"
  )

```


#### Par dépatement
```{r}
rCSI_dept <- Base_Principale %>%
  group_by(ADMIN2Name) %>%
  summarise(rCSI_moyen = mean(rCSI, na.rm = TRUE))

```

```{r}
# Nettoyage des noms côté données
dept_clean <- rCSI_dept %>%
  mutate(ADMIN2_clean = janitor::make_clean_names(ADMIN2Name))

# Nettoyage des noms côté shapefile
shp_dept_clean <- shp_tchad_dep %>%
  mutate(ADM2_FR_clean = janitor::make_clean_names(ADM2_FR))

shp_rCSI_dept <- left_join(shp_dept_clean, dept_clean,
                           by = c("ADM2_FR_clean" = "ADMIN2_clean"))


```

```{r}
# Filtrer uniquement les départements avec données
shp_rCSI_valid_dept <- shp_rCSI_dept %>%
  filter(!is.na(rCSI_moyen))

# Affichage de la carte
ggplot() +
  # Contours de tous les départements
  geom_sf(data = shp_rCSI_dept, fill = NA, color = "grey80", size = 0.4) +

  # Remplissage des départements avec score rCSI
  geom_sf(data = shp_rCSI_valid_dept, aes(fill = rCSI_moyen), color = "white", size = 0.4) +

  # Labels : nom du département + score
  geom_sf_text(
    data = shp_rCSI_valid_dept,
    aes(label = paste0(ADM2_FR, "\n(", round(rCSI_moyen, 1), ")")),
    size = 1.2, fontface = "bold", check_overlap = TRUE
  ) +

  # Palette continue
  scale_fill_viridis_c(option = "C", direction = -1, na.value = "grey90") +

  # Mise en page
  theme_minimal() +
  theme(
    legend.position = "right",
    plot.title = element_text(size = 13, face = "bold", hjust = 0.5),
    plot.subtitle = element_text(size = 10, hjust = 0.5)
  ) +
  labs(
    title = "Indice réduit des stratégies de survie (rCSI) moyen par département",
    subtitle = "Départements sans données visibles uniquement par les contours",
    fill = "rCSI moyen"
  )

```
## Stratégies d'adaptation aux moyens d'existence (LhCSI)
### Analyse descriptive des variables du LhCSI
```{r}


Base_Principale %>%
  mutate(across(
    c(
      LhCSIStress1, LhCSIStress2, LhCSIStress3, LhCSIStress4,
      LhCSICrisis1, LhCSICrisis2, LhCSICrisis3,
      LhCSIEmergency1, LhCSIEmergency2, LhCSIEmergency3
    ),
    ~ to_factor(.)))  %>% 
  select(
    # Stress
    LhCSIStress1, LhCSIStress2, LhCSIStress3, LhCSIStress4,
    # Crise
    LhCSICrisis1, LhCSICrisis2, LhCSICrisis3,
    # Urgence
    LhCSIEmergency1, LhCSIEmergency2, LhCSIEmergency3
  ) %>%
  tbl_summary(
    by = NULL,
    statistic = ~ "{n} ({p}%)",
    missing = "ifany"
  ) %>%
  bold_labels()

```

### Proportion de menage en situation de stress, de crise et d’urgence en 2022 et 2023
```{r}
Base_Principale <- Base_Principale %>%
  mutate(
    LhCSI_urgence = if_any(c(LhCSIEmergency1, LhCSIEmergency2, LhCSIEmergency3), ~ . == 3),
    LhCSI_crise   = if_any(c(LhCSICrisis1, LhCSICrisis2, LhCSICrisis3), ~ . == 3),
    LhCSI_stress  = if_any(c(LhCSIStress1, LhCSIStress2, LhCSIStress3, LhCSIStress4), ~ . == 3),

    LhCSI_severite = case_when(
      LhCSI_urgence ~ "Urgence",
      LhCSI_crise   ~ "Crise",
      LhCSI_stress  ~ "Stress",
      TRUE          ~ "Aucune stratégie"
    )
  )


```

```{r}
library(dplyr)
library(ggplot2)

# Filtrage des années 2022 et 2023
Base_Principale %>%
  filter(YEAR %in% c(2022, 2023)) %>%
  count(YEAR, LhCSI_severite) %>%
  group_by(YEAR) %>%
  mutate(Proportion = round(100 * n / sum(n), 1)) %>%
  ggplot(aes(x = LhCSI_severite, y = Proportion, fill = LhCSI_severite)) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.7), width = 0.6) +
  geom_text(aes(label = paste0(Proportion, "%")),
            position = position_dodge(width = 0.7), vjust = -0.5, size = 3.5) +
  facet_wrap(~YEAR) +
  scale_fill_brewer(palette = "Set2") +
  labs(
    title = "Répartition des ménages par niveau de sévérité (LhCSI)",
    subtitle = "Comparaison entre 2022 et 2023",
    x = "Niveau de sévérité",
    y = "Proportion (%)",
    fill = "Catégorie LhCSI"
  ) +
  theme_minimal() +
  theme(
    strip.text = element_text(size = 11, face = "bold"),
    plot.title = element_text(size = 14, face = "bold", hjust = 0.5),
    plot.subtitle = element_text(size = 11, hjust = 0.5)
  )


```

### Representation spatiale (region et departement) des strategies d’adaptation

#### Representation spatiale par region des strategies d’adaptation
Ici, on représntera les statégies d'adaptation dominante

```{r}
library(dplyr)

lhcsi_region <- Base_Principale %>%
  filter(!is.na(ADMIN1Name)) %>%
  group_by(ADMIN1Name) %>%
  count(LhCSI_severite) %>%
  slice_max(order_by = n, n = 1, with_ties = FALSE) %>%
  rename(severite_dominante = LhCSI_severite) %>%
  mutate(ADMIN1_clean = janitor::make_clean_names(ADMIN1Name))

```

```{r}
shp_region_clean <- shp_tchad_region %>%
  mutate(ADM1_FR_clean = janitor::make_clean_names(ADM1_FR))

shp_lhcsi_region <- left_join(shp_region_clean, lhcsi_region,
                              by = c("ADM1_FR_clean" = "ADMIN1_clean"))

```

```{r}
library(ggplot2)

ggplot(shp_lhcsi_region) +
  geom_sf(aes(fill = severite_dominante), color = "white", size = 0.4) +
  geom_sf_text(aes(label = ADM1_FR), size = 2.5, fontface = "bold", check_overlap = TRUE) +
  scale_fill_brewer(palette = "Set2", na.value = "grey90") +
  labs(
    title = "Stratégie d’adaptation dominante par région (LhCSI)",
    fill = "Niveau de sévérité"
  ) +
  theme_minimal()

```

#### Representation spatiale par département des strategies d’adaptation
```{r}
lhcsi_dept <- Base_Principale %>%
  filter(!is.na(ADMIN2Name)) %>%
  group_by(ADMIN2Name) %>%
  count(LhCSI_severite) %>%
  slice_max(order_by = n, n = 1, with_ties = FALSE) %>%
  rename(severite_dominante = LhCSI_severite) %>%
  mutate(ADMIN2_clean = janitor::make_clean_names(ADMIN2Name))

```

```{r}
shp_dept_clean <- shp_tchad_dep %>%
  mutate(ADM2_FR_clean = janitor::make_clean_names(ADM2_FR))

shp_lhcsi_dep <- left_join(shp_dept_clean, lhcsi_dept,
                            by = c("ADM2_FR_clean" = "ADMIN2_clean"))

```
```{r}
ggplot(shp_lhcsi_dep) +
  geom_sf(aes(fill = severite_dominante), color = "white", size = 0.4) +
  geom_sf_text(aes(label = ADM2_FR), size = 1.8, fontface = "bold", check_overlap = TRUE) +
  scale_fill_brewer(palette = "Set3", na.value = "grey90") +
  labs(
    title = "Stratégie d’adaptation dominante par département (LhCSI)",
    fill = "Niveau de sévérité"
  ) +
  theme_minimal()

```
## Score de diversité alimentaire des ménages

### Analyse descriptive des variables qui composent le SERS
```{r}
sers_vars <- c(
  "SERSRebondir", "SERSRevenue", "SERSMoyen", "SERSDifficultes",
  "SERSSurvivre", "SERSFamAmis", "SERSPoliticiens", "SERSLecons",
  "SERSPreparerFuture", "SERSAvertissementEven"
)

# Conversion des 10 variables en facteurs avec labels textuels
Base_Principale <- Base_Principale %>%
  mutate(across(all_of(sers_vars), to_factor))

Base_Principale %>%
  select(starts_with("SERS")) %>%
  tbl_summary(
    statistic = ~ "{n}",
    missing = "ifany"
  ) %>%
  bold_labels()

```

### Calcul du SERS et création des catégories

```{r}
# Calcul du score total et normalisation min-max entre 0 et 100
Base_Principale <- Base_Principale %>%
  rowwise() %>%
  mutate(
    across(all_of(sers_vars), ~ as.numeric(.)),
    SERS_total = sum(c_across(all_of(sers_vars)), na.rm = TRUE),
    SERS = (SERS_total - 10) / (50 - 10) * 100  # min = 10 (1*10), max = 50 (5*10)
  ) %>%
  ungroup()

# Création des catégories
Base_Principale <- Base_Principale %>%
  mutate(
    SERS_cat = case_when(
      SERS < 33 ~ "Faible",
      SERS >= 33 & SERS < 66 ~ "Moyen",
      SERS >= 66 ~ "Élevé",
      TRUE ~ NA_character_
    )
  )

```

### Représentation spatiale
#### Par région
```{r}
SERS_region <- Base_Principale %>%
  group_by(ADMIN1Name) %>%
  summarise(SERS_moyen = mean(SERS, na.rm = TRUE)) %>%
  mutate(
    SERS_cat_region = case_when(
      SERS_moyen < 33 ~ "Faible",
      SERS_moyen >= 33 & SERS_moyen < 66 ~ "Moyen",
      SERS_moyen >= 66 ~ "Élevé"
    ),
    ADMIN1_clean = janitor::make_clean_names(ADMIN1Name)
  )

```

```{r}
SERS_dept <- Base_Principale %>%
  group_by(ADMIN2Name) %>%
  summarise(SERS_moyen = mean(SERS, na.rm = TRUE)) %>%
  mutate(
    SERS_cat_dept = case_when(
      SERS_moyen < 33 ~ "Faible",
      SERS_moyen >= 33 & SERS_moyen < 66 ~ "Moyen",
      SERS_moyen >= 66 ~ "Élevé"
    ),
    ADMIN2_clean = janitor::make_clean_names(ADMIN2Name)
  )

```

```{r}
shp_region_clean <- shp_tchad_region %>%
  mutate(ADM1_FR_clean = janitor::make_clean_names(ADM1_FR))

shp_sers_region <- left_join(shp_region_clean, SERS_region,
                             by = c("ADM1_FR_clean" = "ADMIN1_clean"))

shp_sers_dept <- left_join(shp_dept_clean, SERS_dept,
                             by = c("ADM2_FR_clean" = "ADMIN2_clean"))

```

```{r}
ggplot(shp_sers_region) +
  geom_sf(aes(fill = SERS_moyen), color = "white") +
  geom_sf_text(aes(label = ADM1_FR), size = 2.5, fontface = "bold", check_overlap = TRUE) +
  scale_fill_viridis_c(option = "C", direction = -1, na.value = "grey90") +
  labs(
    title = "Score moyen de résilience (SERS) par région",
    subtitle = "SERS moyen (0 = faible résilience, 100 = très forte)",
    fill = "SERS moyen"
  ) +
  theme_minimal()

```

```{r}
ggplot(shp_sers_region) +
  geom_sf(aes(fill = SERS_cat_region), color = "white") +
  geom_sf_text(aes(label = ADM1_FR), size = 2.5, fontface = "bold", check_overlap = TRUE) +
  scale_fill_brewer(palette = "YlGnBu", na.value = "grey90") +
  labs(
    title = "Catégorie de résilience (SERS) par région",
    subtitle = "Faible : <33 | Moyen : [33–66) | Élevé : ≥66",
    fill = "Catégorie SERS"
  ) +
  theme_minimal()

```


```{r}
ggplot(shp_sers_dept) +
  geom_sf(aes(fill = SERS_moyen), color = "white") +
  geom_sf_text(aes(label = ADM2_FR), size = 1.8, fontface = "bold", check_overlap = TRUE) +
  scale_fill_viridis_c(option = "C", direction = -1, na.value = "grey90") +
  labs(
    title = "Score moyen de résilience (SERS) par département",
    subtitle = "SERS de 0 (très faible) à 100 (très élevé)",
    fill = "SERS moyen"
  ) +
  theme_minimal()

```

```{r}
ggplot(shp_sers_dept) +
  geom_sf(aes(fill = SERS_cat_dept), color = "white") +
  geom_sf_text(aes(label = ADM2_FR), size = 1.6, fontface = "bold", check_overlap = TRUE) +
  scale_fill_brewer(palette = "YlGnBu", na.value = "grey90") +
  labs(
    title = "Catégorie de résilience (SERS) par département",
    subtitle = "Faible : <33 | Moyen : [33–66) | Élevé : ≥66",
    fill = "Catégorie SERS"
  ) +
  theme_minimal()

```


