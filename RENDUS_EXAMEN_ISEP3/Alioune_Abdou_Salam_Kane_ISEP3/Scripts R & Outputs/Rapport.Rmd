---
title: "Analyse des Données Ménages : Sécurité Alimentaire, Résilience et Conditions de Vie"
author: "Alioune Abdou Salam Kane"
date: "2025-05-10"
output:
  word_document:
    toc: true
    toc_depth: 2
    number_sections: true
    fig_caption: true
---

```{r setup, include=FALSE}
# Configuration globale : ne rien afficher dans le document final
knitr::opts_chunk$set(
  echo = FALSE,        # Ne pas afficher le code
  warning = FALSE,     # Ne pas afficher les warnings
  message = FALSE,     # Ne pas afficher les messages
  results = "hide"     # Ne pas afficher les résultats des chunks (ex : print, tibble, etc.)
)
```




# Introduction

Ce rapport a pour objectif de traiter, analyser et visualiser les données issues d’une enquête ménages portant sur divers aspects de la sécurité alimentaire, des conditions socio-économiques et de la résilience. Il s’inscrit dans un cadre méthodologique rigoureux visant à garantir la qualité, la cohérence et la représentativité des résultats produits.

L’analyse suit une démarche structurée en plusieurs étapes, chacune répondant à des objectifs précis :

1. **Analyse de consistence des données**  
   Vérification de la structure de la base, détection des doublons, traitement des valeurs manquantes, incohérences et imputations.

2. **Analyse des données et calcul d’indicateurs**  
   Estimation des indicateurs clés liés à la sécurité alimentaire, la résilience et les stratégies d’adaptation :
   - Profil socio-démographique des ménages
   - Score de consommation alimentaire (SCA)
   - Indice réduit des stratégies de survie (rCSI)
   - Stratégies d’adaptation aux moyens d'existence (LhCSI)
   - Score de diversité alimentaire (HDDS)
   - Score de résilience auto-évaluée (SERS)
   - Régime alimentaire minimum acceptable (MAD)

3. **Analyse comparative**  
   Mise en évidence des écarts selon le sexe du chef de ménage.

4. **Outil de visualisation**  
   Proposition d’un tableau de bord interactif pour explorer les résultats (R Shiny ou autre outil pertinent).

Chaque section du rapport présentera de manière détaillée les traitements réalisés, les choix méthodologiques adoptés, les résultats obtenus ainsi que leur interprétation.

#  Analyse de consistence des données

## Chargement des packages

Les bibliothèques suivantes sont activées pour permettre toutes les opérations nécessaires :
- `tidyverse` pour manipuler les données,
- `haven` pour importer les données STATA,
- `labelled` pour lire les libellés de variable,
- `janitor` pour nettoyer les noms de colonnes,
- `rlang` pour manipuler dynamiquement les noms de variables.

Le code est masqué à l’exécution, mais ces bibliothèques sont essentielles pour garantir la reproductibilité et la lisibilité des étapes qui suivent.

## Importation de la base et nettoyage

Nous importons la base de données principale située dans le dossier `data/` au format `.dta`. Ensuite, nous nettoyons les noms de colonnes pour les rendre uniformes : minuscules, sans espaces, ni caractères spéciaux. Cela simplifie la manipulation future des données.

## Détection des doublons

L’objectif est d’identifier les éventuelles lignes dupliquées. Une ligne est considérée comme un doublon si toutes ses colonnes ont exactement les mêmes valeurs qu’une autre. Ces doublons, s’ils existent, doivent être traités pour éviter de biaiser les analyses statistiques.

## Exploration des variables et de leurs libellés

Nous générons un tableau recensant l’ensemble des variables de la base, accompagné de leur description (label). Cela facilite la compréhension des données et permet d’identifier rapidement les variables clés pour l’analyse.

## Identification des NA justifiés (sauts logiques)

Certaines valeurs manquantes ne résultent pas d’un oubli ou d’une erreur, mais d’un saut logique dans le questionnaire. Par exemple, un ménage qui n’a pas déclaré de difficultés ne répondra pas aux questions sur les stratégies d’adaptation. Nous mettons en place des règles pour détecter ces cas et éviter de les considérer comme des anomalies.

##  Extraction des NA injustifiés

Une fois les règles logiques établies, nous filtrons les lignes où des variables contiennent des NA injustifiés. Ces NA sont potentiellement problématiques car ils ne devraient pas exister selon la logique du questionnaire. Ils sont donc marqués pour traitement ultérieur.

## Imputation simple des NA suspects

Les NA identifiés comme injustifiés sont imputés selon une méthode simple mais efficace :
- Si la variable est **numérique**, on remplace les NA par la **médiane** de la variable concernée. Cette méthode est robuste face aux valeurs extrêmes.
- Si la variable est **catégorielle**, on remplace les NA par la **modalité la plus fréquente** (le mode). Cela permet de conserver une logique cohérente dans les réponses.

Cette stratégie permet de corriger les données de manière transparente, tout en maintenant une certaine fidélité au profil moyen des ménages observés.


#  Analyse de consistence des données

##  Définition

L’analyse de consistence vise à évaluer la **qualité interne des données**. Il s’agit de détecter :

- des valeurs manquantes problématiques,
- des doublons,
- des incohérences logiques (par exemple, une personne déclarée "homme" et "enceinte"),
- des valeurs aberrantes (comme un âge de 150 ans),
- ou encore des erreurs de saisie typographiques ou hors des échelles prévues.

Cette première étape est cruciale : elle garantit que les résultats ultérieurs reposeront sur une base saine et fiable. Toute anomalie non corrigée pourrait fausser les indicateurs calculés, altérer les interprétations et compromettre la prise de décision.

## Chargement des packages

Les bibliothèques suivantes sont activées pour permettre toutes les opérations nécessaires :
- `tidyverse` pour manipuler les données,
- `haven` pour importer les données STATA,
- `labelled` pour lire les libellés de variable,
- `janitor` pour nettoyer les noms de colonnes,
- `rlang` pour manipuler dynamiquement les noms de variables.

```{r}
# Chargement des bibliothèques nécessaires à l’analyse
library(tidyverse)   # Manipulation et visualisation de données
library(haven)       # Importation des fichiers STATA (.dta)
library(labelled)    # Lecture et gestion des labels
library(janitor)     # Nettoyage des noms de variables
library(rlang)       # Manipulation de noms de colonnes
```

Le code est masqué à l’exécution, mais ces bibliothèques sont essentielles pour garantir la reproductibilité et la lisibilité des étapes qui suivent.

## Importation de la base et nettoyage

Nous importons la base de données principale située dans le dossier `data/` au format `.dta`. Ensuite, nous nettoyons les noms de colonnes pour les rendre uniformes : minuscules, sans espaces, ni caractères spéciaux. Cela simplifie la manipulation future des données.

```{r}
# 1) Assure-toi que R pointe sur la racine du projet
setwd("C:/Users/ALIOUNE KANE/Downloads/Alioune_Abdou_Salam_Kane_ISEP3")

# 2) Importation avec chemin relatif vers le dossier ‘data’
base <- read_dta(file.path("data", "Base_Principale.dta"))

# -------------------- Nettoyage des noms de variables --------------------
# On utilise clean_names() pour rendre tous les noms de variables plus simples :
# minuscules, séparées par des underscores, sans accents ni caractères spéciaux

base <- base %>%
  clean_names()
```

## Détection des doublons

L’objectif est d’identifier les éventuelles lignes dupliquées. Une ligne est considérée comme un doublon si toutes ses colonnes ont exactement les mêmes valeurs qu’une autre. Ces doublons, s’ils existent, doivent être traités pour éviter de biaiser les analyses statistiques.

```{r}
# -------------------- Vérification des doublons --------------------
# On cherche maintenant à identifier s'il existe des lignes dupliquées dans la base.
# Une ligne dupliquée signifie que toutes les valeurs de toutes les colonnes sont identiques
# à une autre ligne, ce qui peut fausser les analyses statistiques.

# Identifier les lignes dupliquées (TRUE si la ligne est un doublon)
doublons_logiques <- duplicated(base)

# Afficher le nombre total de doublons
sum(doublons_logiques)

# Afficher les lignes concernées par les doublons
base[doublons_logiques, ]
```


## Exploration des variables et de leurs libellés

Nous générons un tableau recensant l’ensemble des variables de la base, accompagné de leur description (label). Cela facilite la compréhension des données et permet d’identifier rapidement les variables clés pour l’analyse.

```{r}
# -------------------- Afficher la liste des variables avec leurs labels --------------------
# Ce tableau nous permet de voir la signification de chaque variable (label),
# ce qui est essentiel pour comprendre les dépendances entre variables
# et détecter d’éventuelles incohérences ou non-réponses justifiées (ex: filtre conditionnel).

# Utilise look_for() du package {labelled}
look_for(base) %>%
  select(variable, label)  # Affiche uniquement le nom de la variable et son libellé


# -------------------- Création d'un tableau des variables avec leurs labels --------------------
# Pour mieux comprendre la signification de chaque variable de la base,
# nous allons créer un tableau qui liste, pour chaque variable :
# - son nom technique (ex : HHHAge, HHHSex)
# - sa description (label), telle que définie dans le fichier STATA

# Cela nous permettra ensuite d’identifier des relations logiques possibles entre variables
# (ex : une question qui dépend du sexe ou de l’âge), afin de mieux détecter
# les incohérences, les valeurs manquantes justifiées, ou les erreurs potentielles.

df_labels <- look_for(base) %>%        # Extrait les métadonnées (nom + label)
  select(variable, label) %>%          # Ne garde que le nom et le libellé
  distinct()                           # Évite les doublons s’il y en a

# Visualisation rapide dans la console
head(df_labels)                        # Affiche les premières lignes
```


## Identification des NA justifiés (sauts logiques)

Certaines valeurs manquantes ne résultent pas d’un oubli ou d’une erreur, mais d’un saut logique dans le questionnaire. Par exemple, un ménage qui n’a pas déclaré de difficultés ne répondra pas aux questions sur les stratégies d’adaptation. Nous mettons en place des règles pour détecter ces cas et éviter de les considérer comme des anomalies.


```{r}
# -------------------- Bloc 1 : Identifier les NA attendus (sauts logiques) --------------------
# Dans ce bloc, nous allons indiquer explicitement à R que certaines variables dépendent d'autres.
# Autrement dit, si la réponse à une variable conditionnelle est "non concerné", alors le NA dans
# la variable dépendante n’est pas une erreur de saisie mais un **saut logique normal**.

# Cela permet :
# ✅ D’éviter de faussement considérer ces NA comme des valeurs manquantes à corriger
# ✅ D’expliquer logiquement pourquoi certaines valeurs sont absentes
# ✅ De concentrer les vérifications de qualité uniquement là où c’est pertinent

# Exemple concret : 
# Si un ménage déclare "n’avoir rencontré aucune difficulté" (SERSDifficultes == "Non"),
# alors il est normal que toutes les stratégies de crise (LhCSI*) soient non remplies (NA),
# car ces questions ne lui étaient pas posées.



# -------------------- Objectif de la procédure --------------------
# Nous voulons détecter automatiquement les valeurs manquantes (NA) qui sont :
#  - soit logiquement justifiées (car la question n'était pas posée selon la réponse précédente),
#  - soit injustifiées (et donc à imputer ou analyser comme anomalie).
#
# Pour cela, nous utilisons les "variables maîtresses", c’est-à-dire des variables dont la valeur
# conditionne la présence ou non d’autres questions dans le questionnaire.
#
# ✅ Les modalités de ces variables maîtresses ont été obtenues via STATA :
# 
# SERSDifficultes:
#   1 = tout à fait d'accord
#   2 = d'accord
#   3 = ni d'accord ni pas d'accord
#   4 = pas d'accord
#   5 = pas du tout d'accord
#
# HHHSex:
#   1 = Femme
#   2 = Homme
#
# HHHMainActivity:
#   13 = Don/Aide/Mendicité
#   14 = Autre
#
# Nous utilisons ces modalités pour créer des règles de saut conditionnel.

library(dplyr)
library(rlang)



# -------------------- Définition des règles logiques --------------------
logique_na <- list(
  sers_difficultes = list(
    na_justifie_si = c(1, 2),  # → Si pas de difficulté, pas besoin de poser les questions suivantes
    dependantes = c(
      "lh_csi_stress1", "lh_csi_stress2", "lh_csi_stress3", "lh_csi_stress4",
      "lh_csi_crisis1", "lh_csi_crisis2", "lh_csi_crisis3",
      "lh_csi_emergency1", "lh_csi_emergency2", "lh_csi_emergency3",
      "r_csi_less_qlty", "r_csi_borrow", "r_csi_meal_size", "r_csi_meal_adult", "r_csi_meal_nb"
    )
  ),
  
  hhh_sex = list(
    na_justifie_si = c(2),  # 2 = Homme → certaines questions féminines peuvent être sautées
    dependantes = c()       # À compléter plus tard si des questions spécifiques femmes existent
  ),
  
  hhh_main_activity = list(
    na_justifie_si = c(12, 13, 14),  # Don/Aide/Mendicité ou Autre → pas d'activité structurée
    dependantes = c("hh_source_income")
  )
)

# -------------------- Application automatique des règles --------------------
# Cette boucle crée une colonne de vérification "verif_<nom_variable>" pour chaque variable dépendante,
# indiquant si un NA est "justifié", "suspect" ou si une réponse est présente.

base_verifiee <- base  # Créer une copie de la base pour annotation

for (maitresse in names(logique_na)) {
  config <- logique_na[[maitresse]]
  skip_values <- config$na_justifie_si
  dependantes <- config$dependantes
  
  if (length(dependantes) == 0) next  # on passe si pas de variable dépendante
  
  for (var_dep in dependantes) {
    col_verif <- paste0("verif_", var_dep)
    
    base_verifiee <- base_verifiee %>%
      mutate(!!col_verif := case_when(
        !!sym(maitresse) %in% skip_values & is.na(!!sym(var_dep)) ~ "NA justifié",
        !(!!sym(maitresse) %in% skip_values) & is.na(!!sym(var_dep)) ~ "NA suspect",
        TRUE ~ "Réponse présente"
      ))
  }
}
```

##  Extraction des NA injustifiés

Une fois les règles logiques établies, nous filtrons les lignes où des variables contiennent des NA injustifiés. Ces NA sont potentiellement problématiques car ils ne devraient pas exister selon la logique du questionnaire. Ils sont donc marqués pour traitement ultérieur.

```{r}
# -------------------- Objectif --------------------
# Extraire toutes les lignes de la base où au moins une variable dépendante contient un NA suspect.

library(dplyr)

# 1. Identifier toutes les colonnes de vérification générées précédemment
colonnes_verif <- names(base_verifiee)[grepl("^verif_", names(base_verifiee))]

# 2. Extraire les lignes où au moins un NA est suspect
na_injustifies <- base_verifiee %>%
  filter(if_any(all_of(colonnes_verif), ~ .x == "NA suspect"))

```


## Imputation simple des NA suspects

Les NA identifiés comme injustifiés sont imputés selon une méthode simple mais efficace :
- Si la variable est **numérique**, on remplace les NA par la **médiane** de la variable concernée. Cette méthode est robuste face aux valeurs extrêmes.
- Si la variable est **catégorielle**, on remplace les NA par la **modalité la plus fréquente** (le mode). Cela permet de conserver une logique cohérente dans les réponses.

Cette stratégie permet de corriger les données de manière transparente, tout en maintenant une certaine fidélité au profil moyen des ménages observés.


```{r}
##############################################################################
#  IMPUTATION  DES NA SUSPECTS                              #
#  (On laisse tranquilles les NA justifiés – ils marquent des questions       #
#   qui n’ont jamais été posées.)                                            #
##############################################################################

# Idée générale  :
#   1. Pour CHAQUE colonne dépendante où il reste des “NA suspect”,
#      on remplace ces NA selon un principe évident et facile à expliquer.
#   2. On utilise : 
#        • la MÉDIANE pour les nombres,
#        • la CATÉGORIE LA PLUS FRÉQUENTE (le “mode”) pour les variables
#          qualitatives / ordinales.
#
#   → Pas de machine à gaz ; on choisit la valeur « la plus typique ».
#
# Avantage : compréhensible pour n’importe qui (“on met la valeur la plus
#            répandue / la valeur du milieu”).
# Limite   : moins sophistiqué qu’une vraie imputation multiple,
#             pas idéal mais suffisant 

library(dplyr)

# 1. On crée un data-frame uniquement avec les NA suspects
colonnes_verif <- names(base_verifiee)[grepl("^verif_", names(base_verifiee))]
na_suspects_df <- base_verifiee %>% 
  filter(if_any(all_of(colonnes_verif), ~ .x == "NA suspect"))

# 2. Fonction utilitaire : mode (catégorie la plus fréquente)
mode_simple <- function(x) {
  x <- x[!is.na(x)]
  if (length(x) == 0) return(NA)
  ux <- unique(x)
  ux[which.max(tabulate(match(x, ux)))]
}

# Boucle sur chaque variable dépendante
vars_dependantes <- c(
  "lh_csi_stress1", "lh_csi_stress2", "lh_csi_stress3", "lh_csi_stress4",
  "lh_csi_crisis1", "lh_csi_crisis2", "lh_csi_crisis3",
  "lh_csi_emergency1", "lh_csi_emergency2", "lh_csi_emergency3",
  "r_csi_less_qlty", "r_csi_borrow", "r_csi_meal_size", 
  "r_csi_meal_adult", "r_csi_meal_nb",
  "hh_source_income"
)

# 4. Imputation « basique » colonne par colonne
base_impute_simple <- base_verifiee

for (v in vars_dependantes) {
  
  # repérer seulement les NA suspects
  masque_suspect <- base_verifiee[[paste0("verif_", v)]] == "NA suspect"
  
  if (is.numeric(base_verifiee[[v]])) {
    # ► Cas numérique : on met la médiane (valeur du milieu)
    med <- median(base_verifiee[[v]], na.rm = TRUE)
    base_impute_simple[[v]][masque_suspect] <- med
    
  } else {
    # ► Cas qualitatif / ordinal : on met la catégorie la plus fréquente
    md  <- mode_simple(base_verifiee[[v]])
    base_impute_simple[[v]][masque_suspect] <- md
  }
  
  # On peut conserver un petit drapeau si besoin
  base_impute_simple[[paste0("flag_", v)]] <- dplyr::case_when(
    masque_suspect                    ~ "imputé (simple)",
    TRUE                              ~ "observé / NA justifié"
  )
}

##############################################################################
#  QUE S’EST-IL PASSÉ ? (explication ultra simple)                           #
##############################################################################
# • Pour chaque NA suspect :
#     – Si la colonne est un NOMBRE (par ex. “nombre de repas réduit”),
#       on a mis la MÉDIANE, c’est-à-dire la valeur du milieu quand on trie.
#     – Si la colonne est une CATÉGORIE (par ex. “source principale de revenu”),
#       on a mis la CATÉGORIE LA PLUS COURANTE dans l’ensemble des données.
#
# • Les NA justifiés (liés aux sauts de question) n’ont PAS bougé.
# • On a gardé un petit indicateur flag_<var> pour savoir ce qui a été imputé.
#
#  « on remplace le trou par la valeur la plus représentative. »
##############################################################################
```





##  Vérification des incohérences logiques

Au-delà des valeurs manquantes, certaines réponses peuvent être **présentes mais contradictoires**. Il s’agit de cas où les données renseignées ne respectent pas la logique interne du questionnaire. Nous détaillons ci-dessous les principales incohérences recherchées, ainsi que les principes de correction appliqués. Nous précisions par la même occasion qu'avant d'opérer toute modification sur la base originale nous l'avons dupliqué en amont.

```{r}
# Copie de travail
base_corrigee <- base_verifiee
```


###  Taille du ménage vs somme des tranches d’âge

**Logique** : Le nombre total de membres déclarés (`hh_size`) doit correspondre exactement à la somme des effectifs par tranche d’âge.  
**Correction** : En cas d’écart, nous faisons confiance aux tranches d’âge (plus détaillées) et ajustons la variable `hh_size` en conséquence.

Après vérification , il a été constaté qu'aucune incohérence n'a été détecté concernant les tailles de ménage.

### Difficultés déclarées vs stratégies d’adaptation

**Logique** : Si un ménage déclare ne pas avoir rencontré de difficulté (`sers_difficultes` = 1 ou 2), il ne devrait pas indiquer de stratégies d’adaptation (réduction des repas, vente d’actifs, etc.).  
**Correction** : Les valeurs renseignées dans les variables de stratégie sont remplacées par NA, car ces questions n’auraient pas dû être posées.


###  Consommation alimentaire vs source d’approvisionnement

**Logique** : Lorsqu’un ménage déclare avoir consommé un aliment spécifique (œufs, produits laitiers, fruits…), il doit également indiquer une source d’approvisionnement correspondante (`*_s_rf`).  
**Correction** : Si cette source est absente ou égale à 0 alors que la consommation > 0, on attribue une valeur minimale (1) pour refléter l’obtention effective de l’aliment.

Ces vérifications garantissent une cohérence interne des données, primordiale pour la fiabilité des analyses ultérieures.



```{r}
################################################################################
# 🧩 GESTION DES INCOHÉRENCES DANS LA BASE
################################################################################
# 🎯 OBJECTIF GLOBAL :
# Repérer les incohérences logiques dans les données qui ne relèvent pas
# d’un problème de valeur manquante (NA), mais d’une **valeur remplie fausse**,
# c’est-à-dire une réponse **présente mais absurde ou contradictoire**.

# Exemples : 
#   - Un ménage déclare 5 personnes au total, mais en liste 8 dans les tranches d’âge.
#   - Un ménage dit "ne pas avoir connu de difficulté", mais a adopté des stratégies d’urgence.
#   - Un ménage consomme un aliment, mais dit n’avoir aucune source d’approvisionnement.
#
# Ces erreurs ne peuvent pas être imputées ; il faut soit les corriger, soit les exclure.
# --------------------------------------------------------------------------------
# 🔍 Chaque incohérence sera vérifiée via une règle claire + une colonne "check_..."

library(dplyr)

################################################################################
# 📌 INCOHÉRENCE 1 : Taille du ménage ≠ somme des tranches d’âge
################################################################################
# 🧠 Logique : la somme des membres listés dans les tranches doit être égale à `hh_size`

colonnes_tranches <- c(
  "hh_size05m", "hh_size23m", "hh_size59m", "hh_size5114m", "hh_size1549m", 
  "hh_size5064m", "hh_size65above_m", "hh_size05f", "hh_size23f", "hh_size59f", 
  "hh_size5114f", "hh_size1549f", "hh_size5064f", "hh_size65above_f"
)

base_verifiee <- base_verifiee %>%
  mutate(hh_size_calculee = rowSums(across(all_of(colonnes_tranches)), na.rm = TRUE)) %>%
  mutate(check_hh_size = case_when(
    is.na(hh_size) ~ "taille manquante",
    hh_size == hh_size_calculee ~ "ok",
    TRUE ~ "incohérence"
  ))

################################################################################
# 📌 INCOHÉRENCE 2 : Déclare "pas de difficulté", mais applique des stratégies d'urgence
################################################################################
# 🧠 Logique : si le ménage dit n’avoir eu **aucune difficulté** (valeurs 1 ou 2),
# alors il ne devrait PAS avoir activé de stratégies d’urgence.

strategies_urgence <- c(
  "lh_csi_stress1", "lh_csi_stress2", "lh_csi_stress3", "lh_csi_stress4",
  "lh_csi_crisis1", "lh_csi_crisis2", "lh_csi_crisis3",
  "lh_csi_emergency1", "lh_csi_emergency2", "lh_csi_emergency3",
  "r_csi_less_qlty", "r_csi_borrow", "r_csi_meal_size", 
  "r_csi_meal_adult", "r_csi_meal_nb"
)

base_verifiee <- base_verifiee %>%
  mutate(check_strategies_vs_difficultes = case_when(
    sers_difficultes %in% c(1, 2) &
      rowSums(across(all_of(strategies_urgence)), na.rm = TRUE) > 0 ~ "incohérence",
    TRUE ~ "ok"
  ))

################################################################################
# 📌 INCOHÉRENCE 3 : Consommation alimentaire ≠ Source déclarée
################################################################################
# 🧠 Logique : on ne peut pas consommer un aliment plusieurs jours sans aucune source déclarée.
# Ex : mange des œufs, mais `fcs_pr_s_rf == 0` → incohérent

base_verifiee <- base_verifiee %>%
  mutate(check_fcs_egg = case_when(
    !is.na(fcs_pr_egg) & fcs_pr_egg > 0 & (is.na(fcs_pr_s_rf) | fcs_pr_s_rf == 0) ~ "incohérence",
    TRUE ~ "ok"
  ),
  check_fcs_dairy = case_when(
    !is.na(fcs_dairy) & fcs_dairy > 0 & (is.na(fcs_dairy_s_rf) | fcs_dairy_s_rf == 0) ~ "incohérence",
    TRUE ~ "ok"
  ),
  check_fcs_fruit = case_when(
    !is.na(fcs_fruit) & fcs_fruit > 0 & (is.na(fcs_fruit_s_rf) | fcs_fruit_s_rf == 0) ~ "incohérence",
    TRUE ~ "ok"
  ))

################################################################################
# 📌 INCOHÉRENCE 4 : Sexe du chef de ménage = Homme, mais activité incompatible
################################################################################
# (À adapter si on identifie des activités exclusivement féminines, ex. : allaitement)

# Ici on ne teste rien pour l’instant mais on peut ajouter des règles spécifiques plus tard.

################################################################################
# 📊 AFFICHAGE GLOBAL DES INCOHÉRENCES
################################################################################

# Voir combien d’incohérences par type
table(base_verifiee$check_hh_size)
table(base_verifiee$check_strategies_vs_difficultes)
table(base_verifiee$check_fcs_egg)
table(base_verifiee$check_fcs_dairy)
table(base_verifiee$check_fcs_fruit)

# Extraire les lignes ayant au moins une incohérence
colonnes_check <- names(base_verifiee)[grepl("^check_", names(base_verifiee))]

incoherences_globales <- base_verifiee %>%
  filter(if_any(all_of(colonnes_check), ~ .x == "incohérence"))



###############################################################################
# GESTION DES INCOHÉRENCES DANS LA BASE : CORRECTIONS SIMPLES ET JUSTIFIÉES
###############################################################################
# Ce bloc fait suite aux vérifications faites précédemment.
# Pour chaque incohérence détectée, on :
#   - explique pourquoi c’est incohérent
#   - décide quoi faire
#   - corrige ou marque l’erreur
###############################################################################

# Copie de travail
base_corrigee <- base_verifiee

# 1 - INCOHÉRENCE hh_size ≠ somme des tranches d’âge
# ------------------------------------------------------------
# Pourquoi c’est incohérent :
# Si on dit qu’il y a 6 personnes dans le ménage (hh_size), 
# mais qu’on en a listé 8 dans les tranches d’âges, c’est incohérent.

# Que faire :
# On fait confiance aux tranches détaillées (plus précises),
# donc on corrige hh_size avec la somme calculée.

base_corrigee <- base_corrigee %>%
  mutate(hh_size = ifelse(check_hh_size == "incohérence", hh_size_calculee, hh_size))


# 2 - INCOHÉRENCE : stratégies utilisées alors que ménage dit "pas de difficulté"
# ------------------------------------------------------------
# Pourquoi c’est incohérent :
# Si une personne dit qu’elle n’a pas eu de difficulté (valeurs 1 ou 2),
# mais qu’elle a réduit ses repas ou vendu ses biens, il y a contradiction.

# Que faire :
# On ne peut pas deviner les vraies intentions du ménage.
# Donc on supprime les réponses aux stratégies si la personne dit ne pas avoir eu de difficulté.

base_corrigee <- base_corrigee %>%
  mutate(across(
    all_of(strategies_urgence),
    ~ ifelse(
      check_strategies_vs_difficultes == "incohérence", 
      NA, 
      .
    )
  ))


# 3 - INCOHÉRENCE : consommation d’œufs sans source déclarée
# ------------------------------------------------------------
# Pourquoi c’est incohérent :
# Si quelqu’un dit avoir mangé des œufs, il doit bien les avoir obtenus quelque part.
# fcs_pr_egg > 0 et fcs_pr_s_rf == 0 ne peuvent pas coexister.

# Que faire :
# On ajoute une source par défaut (valeur minimale = 1) dans fcs_pr_s_rf.

base_corrigee <- base_corrigee %>%
  mutate(fcs_pr_s_rf = ifelse(
    check_fcs_egg == "incohérence", 
    1, 
    fcs_pr_s_rf
  ))


# 4 - INCOHÉRENCE : consommation de produits laitiers sans source
# ------------------------------------------------------------
base_corrigee <- base_corrigee %>%
  mutate(fcs_dairy_s_rf = ifelse(
    check_fcs_dairy == "incohérence", 
    1, 
    fcs_dairy_s_rf
  ))


# 5 - INCOHÉRENCE : consommation de fruits sans source
# ------------------------------------------------------------
base_corrigee <- base_corrigee %>%
  mutate(fcs_fruit_s_rf = ifelse(
    check_fcs_fruit == "incohérence", 
    1, 
    fcs_fruit_s_rf
  ))


###############################################################################
# RÉSUMÉ DES CORRECTIONS
###############################################################################
# Pour chaque incohérence, on a appliqué une solution simple :
# - hh_size : remplacé par la vraie somme des membres
# - stratégies : supprimées si personne déclare n’avoir eu aucun problème
# - aliments : ajout d’une source minimale si la personne déclare avoir consommé

# Ces corrections sont raisonnables :
# - elles respectent la logique du questionnaire
# - elles évitent de conserver des valeurs absurdes
# - elles n’inventent pas de réponses aléatoires
###############################################################################
```
# Analyse des données et calcul d’indicateurs

##  Analyse socio-démographique des ménages

Cette section vise à dresser un **profil socio-démographique des chefs de ménage**, stratifié par **sexe** (femme/homme), à travers trois variables essentielles :

- **Âge du chef de ménage** (en années),
- **Taille du ménage** (nombre total de membres),
- **Diplôme le plus élevé obtenu par le chef de ménage**.

L’objectif est de mieux comprendre les caractéristiques de base de la population enquêtée et d’identifier d’éventuelles disparités structurelles selon le sexe du chef de ménage.

### Construction du tableau descriptif

Le tableau ci-dessous a été généré avec la fonction `tbl_summary()` du package `{gtsummary}`. Il fournit :

- Pour les variables **numériques** : la **moyenne** et l’**écart-type**,
- Pour les variables **catégorielles** : l’**effectif** et la **proportion (%)** dans chaque groupe.

Les résultats sont **stratifiés par sexe** afin de comparer les caractéristiques entre les ménages dirigés par des femmes et ceux dirigés par des hommes. Le style est adapté à une sortie propre pour Word grâce à `{flextable}`.

```{r tableau_sociodemo, echo=FALSE, message=FALSE, warning=FALSE}

# TABLEAU SOCIO-DÉMOGRAPHIQUE – Version “Femmes vs Hommes”
# ===============================================================
#
# Objectif : produire un tableau clair et complet des caractéristiques
#            des ménages, stratifié par le sexe du chef de ménage.
#            Les libellés STATA sont automatiquement convertis en facteurs
#            pour afficher « Femme » / « Homme », etc. au lieu des codes.

# 1. Chargement des packages nécessaires
library(tidyverse)
library(haven)
library(labelled)
library(janitor)
library(gtsummary)
library(flextable)

#2. Définir le répertoire de travail principal
setwd("C:/Users/ALIOUNE KANE/Downloads/Alioune_Abdou_Salam_Kane_ISEP3")

# Charger et nettoyer la base corrigée
base_corrigee <- haven::read_dta("data/Base_Principale_corrigee.dta") %>%
  janitor::clean_names() %>%
  dplyr::mutate(across(where(labelled::is.labelled), haven::as_factor))


# 3. Conversion des variables labelisées en facteurs
base_corrigee <- base_corrigee %>%
  mutate(across(
    where(is.labelled), 
    haven::as_factor
  ))

# 4. Sélection des variables à décrire
vars_a_decrire <- c(
  "hhh_age",     # Âge du chef de ménage
  "hh_size",     # Taille du ménage
  "hhh_edu"      # Diplôme le plus élevé
)

# 5. Création du tableau descriptif stratifié
tableau_sociodemo <- base_corrigee %>%
  select(all_of(vars_a_decrire), hhh_sex) %>%
  tbl_summary(
    by = hhh_sex,
    type = list(
      hhh_age ~ "continuous",
      hh_size ~ "continuous"
    ),
    statistic = list(
      all_continuous()  ~ "{mean} ({sd})",
      all_categorical() ~ "{n} ({p}%)"
    ),
    digits = all_continuous() ~ 2,
    label = list(
      hhh_age   ~ "Âge du chef de ménage",
      hh_size   ~ "Taille du ménage",
      hhh_edu   ~ "Diplôme le plus élevé"
    ),
    missing = "ifany"
  ) %>%
  add_n(col_label = "**Effectif**", statistic = "{N_nonmiss}") %>%
  modify_header(
    label  ~ "**Variable**",
    stat_1 ~ "**Femmes**",
    stat_2 ~ "**Hommes**"
  ) %>%
  bold_labels() %>%
  italicize_levels()

# 6. Conversion en flextable pour export Word propre
tableau_sociodemo_ft <- tableau_sociodemo %>%
  as_flex_table() %>%
  flextable::set_table_properties(width = 1, layout = "autofit") %>%
  flextable::fontsize(part = "all", size = 10) %>%
  flextable::padding(padding = 4, part = "all") %>%
  flextable::align(align = "left", part = "all")

# 7. Affichage
tableau_sociodemo_ft
```

Les résultats indiquent des différences notables selon le sexe du chef de ménage.

- **Âge du chef de ménage** : les hommes sont en moyenne plus âgés (45,17 ans) que les femmes (40,09 ans), ce qui peut refléter une structure familiale plus traditionnelle où les hommes prennent la tête du ménage à un âge plus avancé.
  
- **Taille du ménage** : les ménages dirigés par des hommes sont légèrement plus grands (7,75 personnes en moyenne) que ceux dirigés par des femmes (7,29), ce qui peut être lié à des structures familiales plus étendues ou à la cohabitation intergénérationnelle.

- **Diplôme le plus élevé** : les disparités de genre sont marquées. Une majorité de femmes sont alphabétisées ou ont suivi un enseignement coranique (50 %), mais une proportion importante (44 %) n’a aucun diplôme. En revanche, chez les hommes, seuls 21 % sont sans diplôme, et 71 % ont atteint au moins un niveau d’alphabétisation ou coranique. Les niveaux d’enseignement supérieur restent très faibles dans les deux groupes.

En résumé, les chefs de ménage hommes apparaissent globalement plus instruits, plus âgés et à la tête de foyers légèrement plus grands que leurs homologues féminins. Ces écarts peuvent avoir des implications sur l’accès aux ressources, les stratégies de subsistance et la vulnérabilité des ménages.




###  Distribution de la fréquence de consommation des différentes denrées  
*(7 derniers jours – Score de Consommation Alimentaire, SCA)*

```{r sca_tables, echo=FALSE, message=FALSE, warning=FALSE}
# ------------------------------------------------------------------
# 📦 1. PACKAGES
# ------------------------------------------------------------------
library(tidyverse)
library(haven)
library(janitor)
library(labelled)
library(gtsummary)
library(flextable)

# ------------------------------------------------------------------
# 🍽️ 3. VARIABLES SCA
# ------------------------------------------------------------------
vars_sca <- c(
  "fcs_stap", "fcs_pulse", "fcs_dairy", "fcs_pr",
  "fcs_veg",  "fcs_fruit", "fcs_fat",   "fcs_sugar", "fcs_cond"
)

libelles_sca <- list(
  fcs_stap  ~ "Céréales / tubercules (nb. de fois / 7 j)",
  fcs_pulse ~ "Légumineuses (nb. de fois / 7 j)",
  fcs_dairy ~ "Produits laitiers (nb. de fois / 7 j)",
  fcs_pr    ~ "Viande / poisson / œufs (nb. de fois / 7 j)",
  fcs_veg   ~ "Légumes (nb. de fois / 7 j)",
  fcs_fruit ~ "Fruits (nb. de fois / 7 j)",
  fcs_fat   ~ "Graisses / huiles (nb. de fois / 7 j)",
  fcs_sugar ~ "Sucre / sucreries (nb. de fois / 7 j)",
  fcs_cond  ~ "Condiments / épices (nb. de fois / 7 j)"
)

# ------------------------------------------------------------------
# 📊 4-A. TABLEAU GLOBAL
# ------------------------------------------------------------------
tableau_sca_global <- base_corrigee |>
  select(all_of(vars_sca)) |>
  tbl_summary(
    statistic = all_continuous() ~ "{mean} ({sd})",
    digits    = all_continuous() ~ 2,
    label     = libelles_sca,
    missing   = "no"
  ) |>
  add_n(col_label = "**Effectif**") |>
  modify_header(
    label  ~ "**Groupe alimentaire**",
    stat_0 ~ "**Moyenne (écart-type)**"
  ) |>
  bold_labels() |>
  modify_caption(
    "**Distribution de la fréquence de consommation des différentes denrées au cours des 7 derniers jours – Ensemble de l’échantillon**"
  ) |>
  as_flex_table()

# ------------------------------------------------------------------
# 📊 4-B. TABLEAU CROISÉ (Éducation)
# ------------------------------------------------------------------
tableau_sca_edu <- base_corrigee |>
  select(all_of(vars_sca), hhh_edu) |>
  tbl_summary(
    by        = hhh_edu,
    statistic = all_continuous() ~ "{mean} ({sd})",
    digits    = all_continuous() ~ 2,
    label     = libelles_sca,
    missing   = "no"
  ) |>
  add_overall() |>
  add_n(col_label = "**Effectif**") |>
  modify_spanning_header(
    starts_with("stat_") ~ "**Niveau d'éducation du chef de ménage**"
  ) |>
  bold_labels() |>
  modify_caption(
    "**Distribution de la fréquence de consommation des différentes denrées au cours des 7 derniers jours, selon le niveau d'éducation du chef de ménage**"
  ) |>
  as_flex_table()

# ------------------------------------------------------------------
# 👁️ 5. AFFICHAGE DES TABLEAUX
# ------------------------------------------------------------------
tableau_sca_global
tableau_sca_edu
```



La majorité des ménages consomment quotidiennement des céréales. La fréquence de consommation de légumineuses, produits laitiers et protéines animales augmente légèrement avec le niveau d’éducation, suggérant une meilleure connaissance ou un meilleur accès à une alimentation diversifiée chez les chefs de ménage instruits.




## 3. Calcul et présentation de l’indicateur rCSI

Le **Reduced Coping Strategies Index (rCSI)** mesure la fréquence d’adoption de stratégies
comportementales face à l’insécurité alimentaire, sur la base de 5 actions décrites par le PAM.
Nous utilisons ici la version pondérée (somme des poids = 21) pour refléter la gravité relative
de chaque stratégie.

- **Tableau 1** : résumé descriptif du nombre moyen de jours (sur 7) pendant lesquels chaque stratégie a été utilisée.
- **Tableau 2** : poids attribués à chaque stratégie pour le calcul du score pondéré.
- **Tableau 3** : distribution du score rCSI pondéré dans l’échantillon.

Ces tableaux sont interprétables sans connaissance préalable du questionnaire : ils donnent
la fréquence moyenne d’adoption des stratégies et expliquent clairement la méthode de pondération.


