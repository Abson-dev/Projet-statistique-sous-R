---
title: "Analyse des Donn√©es M√©nages : S√©curit√© Alimentaire, R√©silience et Conditions de Vie"
author: "Alioune Abdou Salam Kane"
date: "2025-05-10"
output:
  word_document:
    toc: true
    toc_depth: 2
    number_sections: true
    fig_caption: true
---

```{r setup, include=FALSE}
# Configuration globale : ne rien afficher dans le document final
knitr::opts_chunk$set(
  echo = FALSE,        # Ne pas afficher le code
  warning = FALSE,     # Ne pas afficher les warnings
  message = FALSE,     # Ne pas afficher les messages
  results = "hide"     # Ne pas afficher les r√©sultats des chunks (ex : print, tibble, etc.)
)
```




# Introduction

Ce rapport a pour objectif de traiter, analyser et visualiser les donn√©es issues d‚Äôune enqu√™te m√©nages portant sur divers aspects de la s√©curit√© alimentaire, des conditions socio-√©conomiques et de la r√©silience. Il s‚Äôinscrit dans un cadre m√©thodologique rigoureux visant √† garantir la qualit√©, la coh√©rence et la repr√©sentativit√© des r√©sultats produits.

L‚Äôanalyse suit une d√©marche structur√©e en plusieurs √©tapes, chacune r√©pondant √† des objectifs pr√©cis :

1. **Analyse de consistence des donn√©es**  
   V√©rification de la structure de la base, d√©tection des doublons, traitement des valeurs manquantes, incoh√©rences et imputations.

2. **Analyse des donn√©es et calcul d‚Äôindicateurs**  
   Estimation des indicateurs cl√©s li√©s √† la s√©curit√© alimentaire, la r√©silience et les strat√©gies d‚Äôadaptation :
   - Profil socio-d√©mographique des m√©nages
   - Score de consommation alimentaire (SCA)
   - Indice r√©duit des strat√©gies de survie (rCSI)
   - Strat√©gies d‚Äôadaptation aux moyens d'existence (LhCSI)
   - Score de diversit√© alimentaire (HDDS)
   - Score de r√©silience auto-√©valu√©e (SERS)
   - R√©gime alimentaire minimum acceptable (MAD)

3. **Analyse comparative**  
   Mise en √©vidence des √©carts selon le sexe du chef de m√©nage.

4. **Outil de visualisation**  
   Proposition d‚Äôun tableau de bord interactif pour explorer les r√©sultats (R Shiny ou autre outil pertinent).

Chaque section du rapport pr√©sentera de mani√®re d√©taill√©e les traitements r√©alis√©s, les choix m√©thodologiques adopt√©s, les r√©sultats obtenus ainsi que leur interpr√©tation.

#  Analyse de consistence des donn√©es

## Chargement des packages

Les biblioth√®ques suivantes sont activ√©es pour permettre toutes les op√©rations n√©cessaires :
- `tidyverse` pour manipuler les donn√©es,
- `haven` pour importer les donn√©es STATA,
- `labelled` pour lire les libell√©s de variable,
- `janitor` pour nettoyer les noms de colonnes,
- `rlang` pour manipuler dynamiquement les noms de variables.

Le code est masqu√© √† l‚Äôex√©cution, mais ces biblioth√®ques sont essentielles pour garantir la reproductibilit√© et la lisibilit√© des √©tapes qui suivent.

## Importation de la base et nettoyage

Nous importons la base de donn√©es principale situ√©e dans le dossier `data/` au format `.dta`. Ensuite, nous nettoyons les noms de colonnes pour les rendre uniformes : minuscules, sans espaces, ni caract√®res sp√©ciaux. Cela simplifie la manipulation future des donn√©es.

## D√©tection des doublons

L‚Äôobjectif est d‚Äôidentifier les √©ventuelles lignes dupliqu√©es. Une ligne est consid√©r√©e comme un doublon si toutes ses colonnes ont exactement les m√™mes valeurs qu‚Äôune autre. Ces doublons, s‚Äôils existent, doivent √™tre trait√©s pour √©viter de biaiser les analyses statistiques.

## Exploration des variables et de leurs libell√©s

Nous g√©n√©rons un tableau recensant l‚Äôensemble des variables de la base, accompagn√© de leur description (label). Cela facilite la compr√©hension des donn√©es et permet d‚Äôidentifier rapidement les variables cl√©s pour l‚Äôanalyse.

## Identification des NA justifi√©s (sauts logiques)

Certaines valeurs manquantes ne r√©sultent pas d‚Äôun oubli ou d‚Äôune erreur, mais d‚Äôun saut logique dans le questionnaire. Par exemple, un m√©nage qui n‚Äôa pas d√©clar√© de difficult√©s ne r√©pondra pas aux questions sur les strat√©gies d‚Äôadaptation. Nous mettons en place des r√®gles pour d√©tecter ces cas et √©viter de les consid√©rer comme des anomalies.

##  Extraction des NA injustifi√©s

Une fois les r√®gles logiques √©tablies, nous filtrons les lignes o√π des variables contiennent des NA injustifi√©s. Ces NA sont potentiellement probl√©matiques car ils ne devraient pas exister selon la logique du questionnaire. Ils sont donc marqu√©s pour traitement ult√©rieur.

## Imputation simple des NA suspects

Les NA identifi√©s comme injustifi√©s sont imput√©s selon une m√©thode simple mais efficace :
- Si la variable est **num√©rique**, on remplace les NA par la **m√©diane** de la variable concern√©e. Cette m√©thode est robuste face aux valeurs extr√™mes.
- Si la variable est **cat√©gorielle**, on remplace les NA par la **modalit√© la plus fr√©quente** (le mode). Cela permet de conserver une logique coh√©rente dans les r√©ponses.

Cette strat√©gie permet de corriger les donn√©es de mani√®re transparente, tout en maintenant une certaine fid√©lit√© au profil moyen des m√©nages observ√©s.


#  Analyse de consistence des donn√©es

##  D√©finition

L‚Äôanalyse de consistence vise √† √©valuer la **qualit√© interne des donn√©es**. Il s‚Äôagit de d√©tecter :

- des valeurs manquantes probl√©matiques,
- des doublons,
- des incoh√©rences logiques (par exemple, une personne d√©clar√©e "homme" et "enceinte"),
- des valeurs aberrantes (comme un √¢ge de 150 ans),
- ou encore des erreurs de saisie typographiques ou hors des √©chelles pr√©vues.

Cette premi√®re √©tape est cruciale : elle garantit que les r√©sultats ult√©rieurs reposeront sur une base saine et fiable. Toute anomalie non corrig√©e pourrait fausser les indicateurs calcul√©s, alt√©rer les interpr√©tations et compromettre la prise de d√©cision.

## Chargement des packages

Les biblioth√®ques suivantes sont activ√©es pour permettre toutes les op√©rations n√©cessaires :
- `tidyverse` pour manipuler les donn√©es,
- `haven` pour importer les donn√©es STATA,
- `labelled` pour lire les libell√©s de variable,
- `janitor` pour nettoyer les noms de colonnes,
- `rlang` pour manipuler dynamiquement les noms de variables.

```{r}
# Chargement des biblioth√®ques n√©cessaires √† l‚Äôanalyse
library(tidyverse)   # Manipulation et visualisation de donn√©es
library(haven)       # Importation des fichiers STATA (.dta)
library(labelled)    # Lecture et gestion des labels
library(janitor)     # Nettoyage des noms de variables
library(rlang)       # Manipulation de noms de colonnes
```

Le code est masqu√© √† l‚Äôex√©cution, mais ces biblioth√®ques sont essentielles pour garantir la reproductibilit√© et la lisibilit√© des √©tapes qui suivent.

## Importation de la base et nettoyage

Nous importons la base de donn√©es principale situ√©e dans le dossier `data/` au format `.dta`. Ensuite, nous nettoyons les noms de colonnes pour les rendre uniformes : minuscules, sans espaces, ni caract√®res sp√©ciaux. Cela simplifie la manipulation future des donn√©es.

```{r}
# 1) Assure-toi que R pointe sur la racine du projet
setwd("C:/Users/ALIOUNE KANE/Downloads/Alioune_Abdou_Salam_Kane_ISEP3")

# 2) Importation avec chemin relatif vers le dossier ‚Äòdata‚Äô
base <- read_dta(file.path("data", "Base_Principale.dta"))

# -------------------- Nettoyage des noms de variables --------------------
# On utilise clean_names() pour rendre tous les noms de variables plus simples :
# minuscules, s√©par√©es par des underscores, sans accents ni caract√®res sp√©ciaux

base <- base %>%
  clean_names()
```

## D√©tection des doublons

L‚Äôobjectif est d‚Äôidentifier les √©ventuelles lignes dupliqu√©es. Une ligne est consid√©r√©e comme un doublon si toutes ses colonnes ont exactement les m√™mes valeurs qu‚Äôune autre. Ces doublons, s‚Äôils existent, doivent √™tre trait√©s pour √©viter de biaiser les analyses statistiques.

```{r}
# -------------------- V√©rification des doublons --------------------
# On cherche maintenant √† identifier s'il existe des lignes dupliqu√©es dans la base.
# Une ligne dupliqu√©e signifie que toutes les valeurs de toutes les colonnes sont identiques
# √† une autre ligne, ce qui peut fausser les analyses statistiques.

# Identifier les lignes dupliqu√©es (TRUE si la ligne est un doublon)
doublons_logiques <- duplicated(base)

# Afficher le nombre total de doublons
sum(doublons_logiques)

# Afficher les lignes concern√©es par les doublons
base[doublons_logiques, ]
```


## Exploration des variables et de leurs libell√©s

Nous g√©n√©rons un tableau recensant l‚Äôensemble des variables de la base, accompagn√© de leur description (label). Cela facilite la compr√©hension des donn√©es et permet d‚Äôidentifier rapidement les variables cl√©s pour l‚Äôanalyse.

```{r}
# -------------------- Afficher la liste des variables avec leurs labels --------------------
# Ce tableau nous permet de voir la signification de chaque variable (label),
# ce qui est essentiel pour comprendre les d√©pendances entre variables
# et d√©tecter d‚Äô√©ventuelles incoh√©rences ou non-r√©ponses justifi√©es (ex: filtre conditionnel).

# Utilise look_for() du package {labelled}
look_for(base) %>%
  select(variable, label)  # Affiche uniquement le nom de la variable et son libell√©


# -------------------- Cr√©ation d'un tableau des variables avec leurs labels --------------------
# Pour mieux comprendre la signification de chaque variable de la base,
# nous allons cr√©er un tableau qui liste, pour chaque variable :
# - son nom technique (ex : HHHAge, HHHSex)
# - sa description (label), telle que d√©finie dans le fichier STATA

# Cela nous permettra ensuite d‚Äôidentifier des relations logiques possibles entre variables
# (ex : une question qui d√©pend du sexe ou de l‚Äô√¢ge), afin de mieux d√©tecter
# les incoh√©rences, les valeurs manquantes justifi√©es, ou les erreurs potentielles.

df_labels <- look_for(base) %>%        # Extrait les m√©tadonn√©es (nom + label)
  select(variable, label) %>%          # Ne garde que le nom et le libell√©
  distinct()                           # √âvite les doublons s‚Äôil y en a

# Visualisation rapide dans la console
head(df_labels)                        # Affiche les premi√®res lignes
```


## Identification des NA justifi√©s (sauts logiques)

Certaines valeurs manquantes ne r√©sultent pas d‚Äôun oubli ou d‚Äôune erreur, mais d‚Äôun saut logique dans le questionnaire. Par exemple, un m√©nage qui n‚Äôa pas d√©clar√© de difficult√©s ne r√©pondra pas aux questions sur les strat√©gies d‚Äôadaptation. Nous mettons en place des r√®gles pour d√©tecter ces cas et √©viter de les consid√©rer comme des anomalies.


```{r}
# -------------------- Bloc 1 : Identifier les NA attendus (sauts logiques) --------------------
# Dans ce bloc, nous allons indiquer explicitement √† R que certaines variables d√©pendent d'autres.
# Autrement dit, si la r√©ponse √† une variable conditionnelle est "non concern√©", alors le NA dans
# la variable d√©pendante n‚Äôest pas une erreur de saisie mais un **saut logique normal**.

# Cela permet :
# ‚úÖ D‚Äô√©viter de faussement consid√©rer ces NA comme des valeurs manquantes √† corriger
# ‚úÖ D‚Äôexpliquer logiquement pourquoi certaines valeurs sont absentes
# ‚úÖ De concentrer les v√©rifications de qualit√© uniquement l√† o√π c‚Äôest pertinent

# Exemple concret : 
# Si un m√©nage d√©clare "n‚Äôavoir rencontr√© aucune difficult√©" (SERSDifficultes == "Non"),
# alors il est normal que toutes les strat√©gies de crise (LhCSI*) soient non remplies (NA),
# car ces questions ne lui √©taient pas pos√©es.



# -------------------- Objectif de la proc√©dure --------------------
# Nous voulons d√©tecter automatiquement les valeurs manquantes (NA) qui sont :
#  - soit logiquement justifi√©es (car la question n'√©tait pas pos√©e selon la r√©ponse pr√©c√©dente),
#  - soit injustifi√©es (et donc √† imputer ou analyser comme anomalie).
#
# Pour cela, nous utilisons les "variables ma√Ætresses", c‚Äôest-√†-dire des variables dont la valeur
# conditionne la pr√©sence ou non d‚Äôautres questions dans le questionnaire.
#
# ‚úÖ Les modalit√©s de ces variables ma√Ætresses ont √©t√© obtenues via STATA :
# 
# SERSDifficultes:
#   1 = tout √† fait d'accord
#   2 = d'accord
#   3 = ni d'accord ni pas d'accord
#   4 = pas d'accord
#   5 = pas du tout d'accord
#
# HHHSex:
#   1 = Femme
#   2 = Homme
#
# HHHMainActivity:
#   13 = Don/Aide/Mendicit√©
#   14 = Autre
#
# Nous utilisons ces modalit√©s pour cr√©er des r√®gles de saut conditionnel.

library(dplyr)
library(rlang)



# -------------------- D√©finition des r√®gles logiques --------------------
logique_na <- list(
  sers_difficultes = list(
    na_justifie_si = c(1, 2),  # ‚Üí Si pas de difficult√©, pas besoin de poser les questions suivantes
    dependantes = c(
      "lh_csi_stress1", "lh_csi_stress2", "lh_csi_stress3", "lh_csi_stress4",
      "lh_csi_crisis1", "lh_csi_crisis2", "lh_csi_crisis3",
      "lh_csi_emergency1", "lh_csi_emergency2", "lh_csi_emergency3",
      "r_csi_less_qlty", "r_csi_borrow", "r_csi_meal_size", "r_csi_meal_adult", "r_csi_meal_nb"
    )
  ),
  
  hhh_sex = list(
    na_justifie_si = c(2),  # 2 = Homme ‚Üí certaines questions f√©minines peuvent √™tre saut√©es
    dependantes = c()       # √Ä compl√©ter plus tard si des questions sp√©cifiques femmes existent
  ),
  
  hhh_main_activity = list(
    na_justifie_si = c(12, 13, 14),  # Don/Aide/Mendicit√© ou Autre ‚Üí pas d'activit√© structur√©e
    dependantes = c("hh_source_income")
  )
)

# -------------------- Application automatique des r√®gles --------------------
# Cette boucle cr√©e une colonne de v√©rification "verif_<nom_variable>" pour chaque variable d√©pendante,
# indiquant si un NA est "justifi√©", "suspect" ou si une r√©ponse est pr√©sente.

base_verifiee <- base  # Cr√©er une copie de la base pour annotation

for (maitresse in names(logique_na)) {
  config <- logique_na[[maitresse]]
  skip_values <- config$na_justifie_si
  dependantes <- config$dependantes
  
  if (length(dependantes) == 0) next  # on passe si pas de variable d√©pendante
  
  for (var_dep in dependantes) {
    col_verif <- paste0("verif_", var_dep)
    
    base_verifiee <- base_verifiee %>%
      mutate(!!col_verif := case_when(
        !!sym(maitresse) %in% skip_values & is.na(!!sym(var_dep)) ~ "NA justifi√©",
        !(!!sym(maitresse) %in% skip_values) & is.na(!!sym(var_dep)) ~ "NA suspect",
        TRUE ~ "R√©ponse pr√©sente"
      ))
  }
}
```

##  Extraction des NA injustifi√©s

Une fois les r√®gles logiques √©tablies, nous filtrons les lignes o√π des variables contiennent des NA injustifi√©s. Ces NA sont potentiellement probl√©matiques car ils ne devraient pas exister selon la logique du questionnaire. Ils sont donc marqu√©s pour traitement ult√©rieur.

```{r}
# -------------------- Objectif --------------------
# Extraire toutes les lignes de la base o√π au moins une variable d√©pendante contient un NA suspect.

library(dplyr)

# 1. Identifier toutes les colonnes de v√©rification g√©n√©r√©es pr√©c√©demment
colonnes_verif <- names(base_verifiee)[grepl("^verif_", names(base_verifiee))]

# 2. Extraire les lignes o√π au moins un NA est suspect
na_injustifies <- base_verifiee %>%
  filter(if_any(all_of(colonnes_verif), ~ .x == "NA suspect"))

```


## Imputation simple des NA suspects

Les NA identifi√©s comme injustifi√©s sont imput√©s selon une m√©thode simple mais efficace :
- Si la variable est **num√©rique**, on remplace les NA par la **m√©diane** de la variable concern√©e. Cette m√©thode est robuste face aux valeurs extr√™mes.
- Si la variable est **cat√©gorielle**, on remplace les NA par la **modalit√© la plus fr√©quente** (le mode). Cela permet de conserver une logique coh√©rente dans les r√©ponses.

Cette strat√©gie permet de corriger les donn√©es de mani√®re transparente, tout en maintenant une certaine fid√©lit√© au profil moyen des m√©nages observ√©s.


```{r}
##############################################################################
#  IMPUTATION  DES NA SUSPECTS                              #
#  (On laisse tranquilles les NA justifi√©s ‚Äì ils marquent des questions       #
#   qui n‚Äôont jamais √©t√© pos√©es.)                                            #
##############################################################################

# Id√©e g√©n√©rale  :
#   1. Pour CHAQUE colonne d√©pendante o√π il reste des ‚ÄúNA suspect‚Äù,
#      on remplace ces NA selon un principe √©vident et facile √† expliquer.
#   2. On utilise : 
#        ‚Ä¢ la M√âDIANE pour les nombres,
#        ‚Ä¢ la CAT√âGORIE LA PLUS FR√âQUENTE (le ‚Äúmode‚Äù) pour les variables
#          qualitatives / ordinales.
#
#   ‚Üí Pas de machine √† gaz ; on choisit la valeur ¬´ la plus typique ¬ª.
#
# Avantage : compr√©hensible pour n‚Äôimporte qui (‚Äúon met la valeur la plus
#            r√©pandue / la valeur du milieu‚Äù).
# Limite   : moins sophistiqu√© qu‚Äôune vraie imputation multiple,
#             pas id√©al mais suffisant 

library(dplyr)

# 1. On cr√©e un data-frame uniquement avec les NA suspects
colonnes_verif <- names(base_verifiee)[grepl("^verif_", names(base_verifiee))]
na_suspects_df <- base_verifiee %>% 
  filter(if_any(all_of(colonnes_verif), ~ .x == "NA suspect"))

# 2. Fonction utilitaire : mode (cat√©gorie la plus fr√©quente)
mode_simple <- function(x) {
  x <- x[!is.na(x)]
  if (length(x) == 0) return(NA)
  ux <- unique(x)
  ux[which.max(tabulate(match(x, ux)))]
}

# Boucle sur chaque variable d√©pendante
vars_dependantes <- c(
  "lh_csi_stress1", "lh_csi_stress2", "lh_csi_stress3", "lh_csi_stress4",
  "lh_csi_crisis1", "lh_csi_crisis2", "lh_csi_crisis3",
  "lh_csi_emergency1", "lh_csi_emergency2", "lh_csi_emergency3",
  "r_csi_less_qlty", "r_csi_borrow", "r_csi_meal_size", 
  "r_csi_meal_adult", "r_csi_meal_nb",
  "hh_source_income"
)

# 4. Imputation ¬´ basique ¬ª colonne par colonne
base_impute_simple <- base_verifiee

for (v in vars_dependantes) {
  
  # rep√©rer seulement les NA suspects
  masque_suspect <- base_verifiee[[paste0("verif_", v)]] == "NA suspect"
  
  if (is.numeric(base_verifiee[[v]])) {
    # ‚ñ∫ Cas num√©rique : on met la m√©diane (valeur du milieu)
    med <- median(base_verifiee[[v]], na.rm = TRUE)
    base_impute_simple[[v]][masque_suspect] <- med
    
  } else {
    # ‚ñ∫ Cas qualitatif / ordinal : on met la cat√©gorie la plus fr√©quente
    md  <- mode_simple(base_verifiee[[v]])
    base_impute_simple[[v]][masque_suspect] <- md
  }
  
  # On peut conserver un petit drapeau si besoin
  base_impute_simple[[paste0("flag_", v)]] <- dplyr::case_when(
    masque_suspect                    ~ "imput√© (simple)",
    TRUE                              ~ "observ√© / NA justifi√©"
  )
}

##############################################################################
#  QUE S‚ÄôEST-IL PASS√â ? (explication ultra simple)                           #
##############################################################################
# ‚Ä¢ Pour chaque NA suspect :
#     ‚Äì Si la colonne est un NOMBRE (par ex. ‚Äúnombre de repas r√©duit‚Äù),
#       on a mis la M√âDIANE, c‚Äôest-√†-dire la valeur du milieu quand on trie.
#     ‚Äì Si la colonne est une CAT√âGORIE (par ex. ‚Äúsource principale de revenu‚Äù),
#       on a mis la CAT√âGORIE LA PLUS COURANTE dans l‚Äôensemble des donn√©es.
#
# ‚Ä¢ Les NA justifi√©s (li√©s aux sauts de question) n‚Äôont PAS boug√©.
# ‚Ä¢ On a gard√© un petit indicateur flag_<var> pour savoir ce qui a √©t√© imput√©.
#
#  ¬´ on remplace le trou par la valeur la plus repr√©sentative. ¬ª
##############################################################################
```





##  V√©rification des incoh√©rences logiques

Au-del√† des valeurs manquantes, certaines r√©ponses peuvent √™tre **pr√©sentes mais contradictoires**. Il s‚Äôagit de cas o√π les donn√©es renseign√©es ne respectent pas la logique interne du questionnaire. Nous d√©taillons ci-dessous les principales incoh√©rences recherch√©es, ainsi que les principes de correction appliqu√©s. Nous pr√©cisions par la m√™me occasion qu'avant d'op√©rer toute modification sur la base originale nous l'avons dupliqu√© en amont.

```{r}
# Copie de travail
base_corrigee <- base_verifiee
```


###  Taille du m√©nage vs somme des tranches d‚Äô√¢ge

**Logique** : Le nombre total de membres d√©clar√©s (`hh_size`) doit correspondre exactement √† la somme des effectifs par tranche d‚Äô√¢ge.  
**Correction** : En cas d‚Äô√©cart, nous faisons confiance aux tranches d‚Äô√¢ge (plus d√©taill√©es) et ajustons la variable `hh_size` en cons√©quence.

Apr√®s v√©rification , il a √©t√© constat√© qu'aucune incoh√©rence n'a √©t√© d√©tect√© concernant les tailles de m√©nage.

### Difficult√©s d√©clar√©es vs strat√©gies d‚Äôadaptation

**Logique** : Si un m√©nage d√©clare ne pas avoir rencontr√© de difficult√© (`sers_difficultes` = 1 ou 2), il ne devrait pas indiquer de strat√©gies d‚Äôadaptation (r√©duction des repas, vente d‚Äôactifs, etc.).  
**Correction** : Les valeurs renseign√©es dans les variables de strat√©gie sont remplac√©es par NA, car ces questions n‚Äôauraient pas d√ª √™tre pos√©es.


###  Consommation alimentaire vs source d‚Äôapprovisionnement

**Logique** : Lorsqu‚Äôun m√©nage d√©clare avoir consomm√© un aliment sp√©cifique (≈ìufs, produits laitiers, fruits‚Ä¶), il doit √©galement indiquer une source d‚Äôapprovisionnement correspondante (`*_s_rf`).  
**Correction** : Si cette source est absente ou √©gale √† 0 alors que la consommation > 0, on attribue une valeur minimale (1) pour refl√©ter l‚Äôobtention effective de l‚Äôaliment.

Ces v√©rifications garantissent une coh√©rence interne des donn√©es, primordiale pour la fiabilit√© des analyses ult√©rieures.



```{r}
################################################################################
# üß© GESTION DES INCOH√âRENCES DANS LA BASE
################################################################################
# üéØ OBJECTIF GLOBAL :
# Rep√©rer les incoh√©rences logiques dans les donn√©es qui ne rel√®vent pas
# d‚Äôun probl√®me de valeur manquante (NA), mais d‚Äôune **valeur remplie fausse**,
# c‚Äôest-√†-dire une r√©ponse **pr√©sente mais absurde ou contradictoire**.

# Exemples : 
#   - Un m√©nage d√©clare 5 personnes au total, mais en liste 8 dans les tranches d‚Äô√¢ge.
#   - Un m√©nage dit "ne pas avoir connu de difficult√©", mais a adopt√© des strat√©gies d‚Äôurgence.
#   - Un m√©nage consomme un aliment, mais dit n‚Äôavoir aucune source d‚Äôapprovisionnement.
#
# Ces erreurs ne peuvent pas √™tre imput√©es ; il faut soit les corriger, soit les exclure.
# --------------------------------------------------------------------------------
# üîç Chaque incoh√©rence sera v√©rifi√©e via une r√®gle claire + une colonne "check_..."

library(dplyr)

################################################################################
# üìå INCOH√âRENCE 1 : Taille du m√©nage ‚â† somme des tranches d‚Äô√¢ge
################################################################################
# üß† Logique : la somme des membres list√©s dans les tranches doit √™tre √©gale √† `hh_size`

colonnes_tranches <- c(
  "hh_size05m", "hh_size23m", "hh_size59m", "hh_size5114m", "hh_size1549m", 
  "hh_size5064m", "hh_size65above_m", "hh_size05f", "hh_size23f", "hh_size59f", 
  "hh_size5114f", "hh_size1549f", "hh_size5064f", "hh_size65above_f"
)

base_verifiee <- base_verifiee %>%
  mutate(hh_size_calculee = rowSums(across(all_of(colonnes_tranches)), na.rm = TRUE)) %>%
  mutate(check_hh_size = case_when(
    is.na(hh_size) ~ "taille manquante",
    hh_size == hh_size_calculee ~ "ok",
    TRUE ~ "incoh√©rence"
  ))

################################################################################
# üìå INCOH√âRENCE 2 : D√©clare "pas de difficult√©", mais applique des strat√©gies d'urgence
################################################################################
# üß† Logique : si le m√©nage dit n‚Äôavoir eu **aucune difficult√©** (valeurs 1 ou 2),
# alors il ne devrait PAS avoir activ√© de strat√©gies d‚Äôurgence.

strategies_urgence <- c(
  "lh_csi_stress1", "lh_csi_stress2", "lh_csi_stress3", "lh_csi_stress4",
  "lh_csi_crisis1", "lh_csi_crisis2", "lh_csi_crisis3",
  "lh_csi_emergency1", "lh_csi_emergency2", "lh_csi_emergency3",
  "r_csi_less_qlty", "r_csi_borrow", "r_csi_meal_size", 
  "r_csi_meal_adult", "r_csi_meal_nb"
)

base_verifiee <- base_verifiee %>%
  mutate(check_strategies_vs_difficultes = case_when(
    sers_difficultes %in% c(1, 2) &
      rowSums(across(all_of(strategies_urgence)), na.rm = TRUE) > 0 ~ "incoh√©rence",
    TRUE ~ "ok"
  ))

################################################################################
# üìå INCOH√âRENCE 3 : Consommation alimentaire ‚â† Source d√©clar√©e
################################################################################
# üß† Logique : on ne peut pas consommer un aliment plusieurs jours sans aucune source d√©clar√©e.
# Ex : mange des ≈ìufs, mais `fcs_pr_s_rf == 0` ‚Üí incoh√©rent

base_verifiee <- base_verifiee %>%
  mutate(check_fcs_egg = case_when(
    !is.na(fcs_pr_egg) & fcs_pr_egg > 0 & (is.na(fcs_pr_s_rf) | fcs_pr_s_rf == 0) ~ "incoh√©rence",
    TRUE ~ "ok"
  ),
  check_fcs_dairy = case_when(
    !is.na(fcs_dairy) & fcs_dairy > 0 & (is.na(fcs_dairy_s_rf) | fcs_dairy_s_rf == 0) ~ "incoh√©rence",
    TRUE ~ "ok"
  ),
  check_fcs_fruit = case_when(
    !is.na(fcs_fruit) & fcs_fruit > 0 & (is.na(fcs_fruit_s_rf) | fcs_fruit_s_rf == 0) ~ "incoh√©rence",
    TRUE ~ "ok"
  ))

################################################################################
# üìå INCOH√âRENCE 4 : Sexe du chef de m√©nage = Homme, mais activit√© incompatible
################################################################################
# (√Ä adapter si on identifie des activit√©s exclusivement f√©minines, ex. : allaitement)

# Ici on ne teste rien pour l‚Äôinstant mais on peut ajouter des r√®gles sp√©cifiques plus tard.

################################################################################
# üìä AFFICHAGE GLOBAL DES INCOH√âRENCES
################################################################################

# Voir combien d‚Äôincoh√©rences par type
table(base_verifiee$check_hh_size)
table(base_verifiee$check_strategies_vs_difficultes)
table(base_verifiee$check_fcs_egg)
table(base_verifiee$check_fcs_dairy)
table(base_verifiee$check_fcs_fruit)

# Extraire les lignes ayant au moins une incoh√©rence
colonnes_check <- names(base_verifiee)[grepl("^check_", names(base_verifiee))]

incoherences_globales <- base_verifiee %>%
  filter(if_any(all_of(colonnes_check), ~ .x == "incoh√©rence"))



###############################################################################
# GESTION DES INCOH√âRENCES DANS LA BASE : CORRECTIONS SIMPLES ET JUSTIFI√âES
###############################################################################
# Ce bloc fait suite aux v√©rifications faites pr√©c√©demment.
# Pour chaque incoh√©rence d√©tect√©e, on :
#   - explique pourquoi c‚Äôest incoh√©rent
#   - d√©cide quoi faire
#   - corrige ou marque l‚Äôerreur
###############################################################################

# Copie de travail
base_corrigee <- base_verifiee

# 1 - INCOH√âRENCE hh_size ‚â† somme des tranches d‚Äô√¢ge
# ------------------------------------------------------------
# Pourquoi c‚Äôest incoh√©rent :
# Si on dit qu‚Äôil y a 6 personnes dans le m√©nage (hh_size), 
# mais qu‚Äôon en a list√© 8 dans les tranches d‚Äô√¢ges, c‚Äôest incoh√©rent.

# Que faire :
# On fait confiance aux tranches d√©taill√©es (plus pr√©cises),
# donc on corrige hh_size avec la somme calcul√©e.

base_corrigee <- base_corrigee %>%
  mutate(hh_size = ifelse(check_hh_size == "incoh√©rence", hh_size_calculee, hh_size))


# 2 - INCOH√âRENCE : strat√©gies utilis√©es alors que m√©nage dit "pas de difficult√©"
# ------------------------------------------------------------
# Pourquoi c‚Äôest incoh√©rent :
# Si une personne dit qu‚Äôelle n‚Äôa pas eu de difficult√© (valeurs 1 ou 2),
# mais qu‚Äôelle a r√©duit ses repas ou vendu ses biens, il y a contradiction.

# Que faire :
# On ne peut pas deviner les vraies intentions du m√©nage.
# Donc on supprime les r√©ponses aux strat√©gies si la personne dit ne pas avoir eu de difficult√©.

base_corrigee <- base_corrigee %>%
  mutate(across(
    all_of(strategies_urgence),
    ~ ifelse(
      check_strategies_vs_difficultes == "incoh√©rence", 
      NA, 
      .
    )
  ))


# 3 - INCOH√âRENCE : consommation d‚Äô≈ìufs sans source d√©clar√©e
# ------------------------------------------------------------
# Pourquoi c‚Äôest incoh√©rent :
# Si quelqu‚Äôun dit avoir mang√© des ≈ìufs, il doit bien les avoir obtenus quelque part.
# fcs_pr_egg > 0 et fcs_pr_s_rf == 0 ne peuvent pas coexister.

# Que faire :
# On ajoute une source par d√©faut (valeur minimale = 1) dans fcs_pr_s_rf.

base_corrigee <- base_corrigee %>%
  mutate(fcs_pr_s_rf = ifelse(
    check_fcs_egg == "incoh√©rence", 
    1, 
    fcs_pr_s_rf
  ))


# 4 - INCOH√âRENCE : consommation de produits laitiers sans source
# ------------------------------------------------------------
base_corrigee <- base_corrigee %>%
  mutate(fcs_dairy_s_rf = ifelse(
    check_fcs_dairy == "incoh√©rence", 
    1, 
    fcs_dairy_s_rf
  ))


# 5 - INCOH√âRENCE : consommation de fruits sans source
# ------------------------------------------------------------
base_corrigee <- base_corrigee %>%
  mutate(fcs_fruit_s_rf = ifelse(
    check_fcs_fruit == "incoh√©rence", 
    1, 
    fcs_fruit_s_rf
  ))


###############################################################################
# R√âSUM√â DES CORRECTIONS
###############################################################################
# Pour chaque incoh√©rence, on a appliqu√© une solution simple :
# - hh_size : remplac√© par la vraie somme des membres
# - strat√©gies : supprim√©es si personne d√©clare n‚Äôavoir eu aucun probl√®me
# - aliments : ajout d‚Äôune source minimale si la personne d√©clare avoir consomm√©

# Ces corrections sont raisonnables :
# - elles respectent la logique du questionnaire
# - elles √©vitent de conserver des valeurs absurdes
# - elles n‚Äôinventent pas de r√©ponses al√©atoires
###############################################################################
```
# Analyse des donn√©es et calcul d‚Äôindicateurs

##  Analyse socio-d√©mographique des m√©nages

Cette section vise √† dresser un **profil socio-d√©mographique des chefs de m√©nage**, stratifi√© par **sexe** (femme/homme), √† travers trois variables essentielles :

- **√Çge du chef de m√©nage** (en ann√©es),
- **Taille du m√©nage** (nombre total de membres),
- **Dipl√¥me le plus √©lev√© obtenu par le chef de m√©nage**.

L‚Äôobjectif est de mieux comprendre les caract√©ristiques de base de la population enqu√™t√©e et d‚Äôidentifier d‚Äô√©ventuelles disparit√©s structurelles selon le sexe du chef de m√©nage.

### Construction du tableau descriptif

Le tableau ci-dessous a √©t√© g√©n√©r√© avec la fonction `tbl_summary()` du package `{gtsummary}`. Il fournit :

- Pour les variables **num√©riques** : la **moyenne** et l‚Äô**√©cart-type**,
- Pour les variables **cat√©gorielles** : l‚Äô**effectif** et la **proportion (%)** dans chaque groupe.

Les r√©sultats sont **stratifi√©s par sexe** afin de comparer les caract√©ristiques entre les m√©nages dirig√©s par des femmes et ceux dirig√©s par des hommes. Le style est adapt√© √† une sortie propre pour Word gr√¢ce √† `{flextable}`.

```{r tableau_sociodemo, echo=FALSE, message=FALSE, warning=FALSE}

# TABLEAU SOCIO-D√âMOGRAPHIQUE ‚Äì Version ‚ÄúFemmes vs Hommes‚Äù
# ===============================================================
#
# Objectif : produire un tableau clair et complet des caract√©ristiques
#            des m√©nages, stratifi√© par le sexe du chef de m√©nage.
#            Les libell√©s STATA sont automatiquement convertis en facteurs
#            pour afficher ¬´ Femme ¬ª / ¬´ Homme ¬ª, etc. au lieu des codes.

# 1. Chargement des packages n√©cessaires
library(tidyverse)
library(haven)
library(labelled)
library(janitor)
library(gtsummary)
library(flextable)

#2. D√©finir le r√©pertoire de travail principal
setwd("C:/Users/ALIOUNE KANE/Downloads/Alioune_Abdou_Salam_Kane_ISEP3")

# Charger et nettoyer la base corrig√©e
base_corrigee <- haven::read_dta("data/Base_Principale_corrigee.dta") %>%
  janitor::clean_names() %>%
  dplyr::mutate(across(where(labelled::is.labelled), haven::as_factor))


# 3. Conversion des variables labelis√©es en facteurs
base_corrigee <- base_corrigee %>%
  mutate(across(
    where(is.labelled), 
    haven::as_factor
  ))

# 4. S√©lection des variables √† d√©crire
vars_a_decrire <- c(
  "hhh_age",     # √Çge du chef de m√©nage
  "hh_size",     # Taille du m√©nage
  "hhh_edu"      # Dipl√¥me le plus √©lev√©
)

# 5. Cr√©ation du tableau descriptif stratifi√©
tableau_sociodemo <- base_corrigee %>%
  select(all_of(vars_a_decrire), hhh_sex) %>%
  tbl_summary(
    by = hhh_sex,
    type = list(
      hhh_age ~ "continuous",
      hh_size ~ "continuous"
    ),
    statistic = list(
      all_continuous()  ~ "{mean} ({sd})",
      all_categorical() ~ "{n} ({p}%)"
    ),
    digits = all_continuous() ~ 2,
    label = list(
      hhh_age   ~ "√Çge du chef de m√©nage",
      hh_size   ~ "Taille du m√©nage",
      hhh_edu   ~ "Dipl√¥me le plus √©lev√©"
    ),
    missing = "ifany"
  ) %>%
  add_n(col_label = "**Effectif**", statistic = "{N_nonmiss}") %>%
  modify_header(
    label  ~ "**Variable**",
    stat_1 ~ "**Femmes**",
    stat_2 ~ "**Hommes**"
  ) %>%
  bold_labels() %>%
  italicize_levels()

# 6. Conversion en flextable pour export Word propre
tableau_sociodemo_ft <- tableau_sociodemo %>%
  as_flex_table() %>%
  flextable::set_table_properties(width = 1, layout = "autofit") %>%
  flextable::fontsize(part = "all", size = 10) %>%
  flextable::padding(padding = 4, part = "all") %>%
  flextable::align(align = "left", part = "all")

# 7. Affichage
tableau_sociodemo_ft
```

Les r√©sultats indiquent des diff√©rences notables selon le sexe du chef de m√©nage.

- **√Çge du chef de m√©nage** : les hommes sont en moyenne plus √¢g√©s (45,17 ans) que les femmes (40,09 ans), ce qui peut refl√©ter une structure familiale plus traditionnelle o√π les hommes prennent la t√™te du m√©nage √† un √¢ge plus avanc√©.
  
- **Taille du m√©nage** : les m√©nages dirig√©s par des hommes sont l√©g√®rement plus grands (7,75 personnes en moyenne) que ceux dirig√©s par des femmes (7,29), ce qui peut √™tre li√© √† des structures familiales plus √©tendues ou √† la cohabitation interg√©n√©rationnelle.

- **Dipl√¥me le plus √©lev√©** : les disparit√©s de genre sont marqu√©es. Une majorit√© de femmes sont alphab√©tis√©es ou ont suivi un enseignement coranique (50 %), mais une proportion importante (44 %) n‚Äôa aucun dipl√¥me. En revanche, chez les hommes, seuls 21 % sont sans dipl√¥me, et 71 % ont atteint au moins un niveau d‚Äôalphab√©tisation ou coranique. Les niveaux d‚Äôenseignement sup√©rieur restent tr√®s faibles dans les deux groupes.

En r√©sum√©, les chefs de m√©nage hommes apparaissent globalement plus instruits, plus √¢g√©s et √† la t√™te de foyers l√©g√®rement plus grands que leurs homologues f√©minins. Ces √©carts peuvent avoir des implications sur l‚Äôacc√®s aux ressources, les strat√©gies de subsistance et la vuln√©rabilit√© des m√©nages.




###  Distribution de la fr√©quence de consommation des diff√©rentes denr√©es  
*(7 derniers jours ‚Äì Score de Consommation Alimentaire, SCA)*

```{r sca_tables, echo=FALSE, message=FALSE, warning=FALSE}
# ------------------------------------------------------------------
# üì¶ 1. PACKAGES
# ------------------------------------------------------------------
library(tidyverse)
library(haven)
library(janitor)
library(labelled)
library(gtsummary)
library(flextable)

# ------------------------------------------------------------------
# üçΩÔ∏è 3. VARIABLES SCA
# ------------------------------------------------------------------
vars_sca <- c(
  "fcs_stap", "fcs_pulse", "fcs_dairy", "fcs_pr",
  "fcs_veg",  "fcs_fruit", "fcs_fat",   "fcs_sugar", "fcs_cond"
)

libelles_sca <- list(
  fcs_stap  ~ "C√©r√©ales / tubercules (nb. de fois / 7 j)",
  fcs_pulse ~ "L√©gumineuses (nb. de fois / 7 j)",
  fcs_dairy ~ "Produits laitiers (nb. de fois / 7 j)",
  fcs_pr    ~ "Viande / poisson / ≈ìufs (nb. de fois / 7 j)",
  fcs_veg   ~ "L√©gumes (nb. de fois / 7 j)",
  fcs_fruit ~ "Fruits (nb. de fois / 7 j)",
  fcs_fat   ~ "Graisses / huiles (nb. de fois / 7 j)",
  fcs_sugar ~ "Sucre / sucreries (nb. de fois / 7 j)",
  fcs_cond  ~ "Condiments / √©pices (nb. de fois / 7 j)"
)

# ------------------------------------------------------------------
# üìä 4-A. TABLEAU GLOBAL
# ------------------------------------------------------------------
tableau_sca_global <- base_corrigee |>
  select(all_of(vars_sca)) |>
  tbl_summary(
    statistic = all_continuous() ~ "{mean} ({sd})",
    digits    = all_continuous() ~ 2,
    label     = libelles_sca,
    missing   = "no"
  ) |>
  add_n(col_label = "**Effectif**") |>
  modify_header(
    label  ~ "**Groupe alimentaire**",
    stat_0 ~ "**Moyenne (√©cart-type)**"
  ) |>
  bold_labels() |>
  modify_caption(
    "**Distribution de la fr√©quence de consommation des diff√©rentes denr√©es au cours des 7 derniers jours ‚Äì Ensemble de l‚Äô√©chantillon**"
  ) |>
  as_flex_table()

# ------------------------------------------------------------------
# üìä 4-B. TABLEAU CROIS√â (√âducation)
# ------------------------------------------------------------------
tableau_sca_edu <- base_corrigee |>
  select(all_of(vars_sca), hhh_edu) |>
  tbl_summary(
    by        = hhh_edu,
    statistic = all_continuous() ~ "{mean} ({sd})",
    digits    = all_continuous() ~ 2,
    label     = libelles_sca,
    missing   = "no"
  ) |>
  add_overall() |>
  add_n(col_label = "**Effectif**") |>
  modify_spanning_header(
    starts_with("stat_") ~ "**Niveau d'√©ducation du chef de m√©nage**"
  ) |>
  bold_labels() |>
  modify_caption(
    "**Distribution de la fr√©quence de consommation des diff√©rentes denr√©es au cours des 7 derniers jours, selon le niveau d'√©ducation du chef de m√©nage**"
  ) |>
  as_flex_table()

# ------------------------------------------------------------------
# üëÅÔ∏è 5. AFFICHAGE DES TABLEAUX
# ------------------------------------------------------------------
tableau_sca_global
tableau_sca_edu
```



La majorit√© des m√©nages consomment quotidiennement des c√©r√©ales. La fr√©quence de consommation de l√©gumineuses, produits laitiers et prot√©ines animales augmente l√©g√®rement avec le niveau d‚Äô√©ducation, sugg√©rant une meilleure connaissance ou un meilleur acc√®s √† une alimentation diversifi√©e chez les chefs de m√©nage instruits.




## 3. Calcul et pr√©sentation de l‚Äôindicateur rCSI

Le **Reduced Coping Strategies Index (rCSI)** mesure la fr√©quence d‚Äôadoption de strat√©gies
comportementales face √† l‚Äôins√©curit√© alimentaire, sur la base de 5 actions d√©crites par le PAM.
Nous utilisons ici la version pond√©r√©e (somme des poids = 21) pour refl√©ter la gravit√© relative
de chaque strat√©gie.

- **Tableau 1** : r√©sum√© descriptif du nombre moyen de jours (sur 7) pendant lesquels chaque strat√©gie a √©t√© utilis√©e.
- **Tableau 2** : poids attribu√©s √† chaque strat√©gie pour le calcul du score pond√©r√©.
- **Tableau 3** : distribution du score rCSI pond√©r√© dans l‚Äô√©chantillon.

Ces tableaux sont interpr√©tables sans connaissance pr√©alable du questionnaire : ils donnent
la fr√©quence moyenne d‚Äôadoption des strat√©gies et expliquent clairement la m√©thode de pond√©ration.


