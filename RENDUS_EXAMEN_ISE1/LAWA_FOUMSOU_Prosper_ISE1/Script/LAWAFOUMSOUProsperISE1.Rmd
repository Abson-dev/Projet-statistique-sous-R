---
title: ""
output:
  word_document:
    toc_depth: 3        # Profondeur (titres de niveau 1 et 2)
    reference_docx: ../Documents/word_template.docx #modele de référence
    keep_md: true
    #pandoc_args: ["--output=../Sorties/Maquette_evaluation_R_word.docx"] #définir le lieu de sortie
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, 
                      cache = TRUE,
                      warning = FALSE, 
                      message = FALSE,
                      comment = NA)

```

```{r}

#Installation et importation des packages

# Liste des packages nécessaires
packages <- c(
  "tidyverse",   # Manipulation & visualisation de données : inclut : ggplot2, dplyr, tidyr, readr, purrr, tibble, stringr, forcats
  "janitor",     # Nettoyage des données
  "gtsummary",   # Tableaux statistiques formatés pour Word/HTML
  "sf",          # Données spatiales (cartographie, shapefiles)
  "haven",      # Lecture de fichiers stata(.dta)
  "flextable",   # Mise en forme avancée de tableaux Word
  "officer",     # Interaction avec Word (officedown)
  "officedown",   # Intégration R Markdown → Word enrichi
  "sf"
)

for (package in packages) {
  if (!requireNamespace(package, quietly = TRUE)) {   # Vérifie si le package n'est pas encore installé
    install.packages(package)
  }
  library(package, character.only = TRUE) # nom du package en nom ou chaine de caractère ()
}
```

```{r page_garde_1}

flextable(data.frame(Contenu = "REPUBLIQUE DU SENEGAL")) %>% #Créer un tableau flextable
  delete_part(part = "header") %>% #supprimer l'en-tête
  border_remove() %>% #Supprimer les bordures
  
  # Application de la police
  font(fontname = "Times New Roman", part = "all") %>% 
  fontsize(size = 14, part = "all") %>% 
  
  # Mise en forme du texte
  bold(i = 1, j = 1) %>% 
  align(align = "center") %>% 
  
  set_table_properties(layout = "autofit", width = 1) #Ajuste la largeur des colonnes automatiquements

```

|                                                            |
|:----------------------------------------------------------:|
| ![](../Documents/Logo%20SEN.png){width="3cm" height="3cm"} |

```{r page_garde_2}

flextable(data.frame(Contenu = c( "**********",
                                  "Un Peuple - Un But - Une Foi",
                                  "**********",
                                  "Agence nationale de la Statistique et de la démographie"))) %>% 
  delete_part(part = "header") %>% 
  border_remove() %>% 
  
  # Application de la police
  font(fontname = "Times New Roman", part = "all") %>% 
  fontsize(size = 14, part = "all") %>%
  
  # Mise en forme du texte
  bold(i = 1:4, j = 1) %>% 
  italic(i = 2, j = 1) %>% 
  align(align = "center") %>% 
  
  set_table_properties(layout = "autofit", width = 1)

```

|                                                |
|:----------------------------------------------:|
| ![](../Documents/Logo-ANSD.png){width="3.5cm"} |

```{r page_garde_3}

flextable(data.frame(Contenu = c("**********",
                                  "Ecole nationale de la Statistique et de l'Analyse économique Pierre Ndiaye"))) %>%
  delete_part(part = "header") %>% 
  border_remove() %>% 
  
  # Application de la police
  font(fontname = "Times New Roman", part = "all") %>% 
  fontsize(size = 14, part = "all") %>% 
  
  # Mise en forme du texte
  bold(i = 1:2, j = 1) %>% 
  align(align = "center") %>% 
  
  set_table_properties(layout = "autofit", width = 1)

```

|                                                                    |
|:------------------------------------------------------------------:|
| ![](../Documents/ENSAE-Dakar-logo.png){width="2.5cm" height="2cm"} |

##### Projet statistique sur R : Evaluation

```{r page garde_4,include=FALSE}

flextable(data.frame(Contenu = "Projet statistique avec R")) %>%
  delete_part(part = "header") %>% 
  border_remove() %>% 
  
  # Application de la police
  font(fontname = "Times New Roman", part = "all") %>% 
  fontsize(size = 15, part = "all") %>% 
  
  # Mise en forme du texte
  italic(i = 1, j = 1) %>% 
  align(align = "center") %>% 
  
  set_table_properties(layout = "autofit", width = 1)

```

 

 

```{r page_garde_5}
donnees <- data.frame(
  col1 = c("Rédigé par", "LAWA FOUMSOU Prosper", "Élève Ingénieur Statisticien Économiste"),
  col2 = c("Sous la supervision de", "M. Aboubacar HEMA", "Data-scientist"),
  stringsAsFactors = FALSE
)
flextable(donnees) %>% 
  delete_part(part = "header") %>% 
  width(j = 1:2, width = 0.5) %>%  # Répartition égale de la largeur
  align(j = 1, align = "left") %>% 
  align(j = 2, align = "right") %>% 
  border_remove() %>% 
  bold(i = 1, j = 1:2) %>% 
  italic(i = 3, j = 1:2) %>% 
  set_table_properties(layout = "autofit", width = 1) %>%  # Force la largeur totale
  fontsize(size = 11)  # Ajuste la taille de police si nécessaire

```

 

 

|                                |
|:------------------------------:|
| **Année académique 2024-2025** |

\newpage

###### Sommaire

N'est pas généré automatiquement donc le faire directement avec word.

<!---BLOCK_TOC--->

\newpage

###### Liste des figures

<!---BLOCK_TOC{seq_id: 'fig'}--->

N'est pas généré automatiquement donc le faire directement avec word.

\newpage

###### Liste des tableaux

N'est pas généré automatiquement donc le faire directement avec word.

<!---BLOCK_TOC{seq_id: 'tab'}--->

\newpage

# Introduction

Cette étude s'inscrit dans le cadre de l'**Enquête sur les déplacements forcés au Sud-Soudan menée en 2023**, un pays affecté par des crises humanitaires prolongées dues à des conflits armés, des catastrophes naturelles et des déplacements massifs de population. Ces dynamiques ont eu un impact significatif sur la sécurité alimentaire des ménages, en particulier parmi les populations déplacées internes (IDPs).

L'objectif principal de cette analyse est d'évaluer la qualité de la consommation alimentaire des ménages à l'aide du **Score de Consommation Alimentaire (SCA)**, un indicateur développé par le **Programme Alimentaire Mondial (PAM)**. Ce score combine la diversité alimentaire, la fréquence de consommation et la valeur nutritionnelle des groupes alimentaires consommés durant les 7 derniers jours.

L’utilisation de **R** permet d’effectuer un traitement reproductible des données, de calculer le SCA selon les normes du PAM, et de classifier les ménages en fonction de leur niveau de sécurité alimentaire. Cette analyse repose sur les seuils adaptés au contexte du **Sud-Soudan**, en tenant compte des recommandations techniques du PAM en matière de classification.

Les résultats obtenus permettront d’identifier les ménages les plus vulnérables en matière d'accès à une alimentation adéquate et d’orienter les interventions humanitaires de manière ciblée et efficace.

\newpage

# I. Importation et Analyse de consistance des bases

## 1. Importation des jeux de données

```{r, import-data, results='hide',include=FALSE}
#importations
principal_dataset <-  haven::read_dta("../donnees/Base_Principale.dta") %>%  # Importation de la base mad
  janitor::clean_names() #Nettoyage des noms de variables

Individus_dataset <-  haven::read_dta("../donnees/Base_Individus.dta") %>% 
  janitor::clean_names()

## Pour meiux voir toutes les modalités des variables
principal_dataset <- labelled::to_factor(principal_dataset)

Individus_dataset <- labelled::to_factor(Individus_dataset)
```

Commençons par avoir une idée du nombre de variables et d'observations dans chaque base.

### Base principale

```{r,include=FALSE}
glimpse(principal_dataset)
```

La base principale a `r nrow(principal_dataset)` lignes et `r ncol(principal_dataset)` colonnes.

### Base MAD

```{r,include=FALSE}
glimpse(Individus_dataset)
```

La base individus a `r nrow(Individus_dataset)` lignes et `r nrow(Individus_dataset)` colonnes.

# II. Analyse de consistance des bases

```{r}
# Suppression de colonnes vides
principal_dataset <- principal_dataset %>% 
  janitor::remove_empty(which = c("rows", "cols"))

Individus_dataset <- Individus_dataset %>% janitor::remove_empty(which = c("rows", "cols"))
```

La base principale a `r nrow(principal_dataset)` lignes et `r ncol(principal_dataset)` colonnes après suppression de colonnes vides.La base individus a `r nrow(Individus_dataset)` lignes et `r nrow(Individus_dataset)` colonnes après suppression de colonnes vides.

## Detection de doublons

On remarque qi'il n' y a pas de doublons dans la base principale

```{r,results='hide'}
# Identification du nombre de duplication dans la base principale. 
janitor::get_dupes(principal_dataset)
```

Aussi on remarque qu'il n'y a pas de doublons dans la base individus. Passons donc au traitement des données manquantes

```{r, include=FALSE}
# Identification du nombre de duplication dans la base individu 
janitor::get_dupes(Individus_dataset)
```

## Traitement de données manquantes

```{r dbl1,results='hide'}
table_manquant1 <- principal_dataset %>%
  naniar::miss_var_summary() %>%         # Résumé du nombre et pourcentage de valeurs manquantes par variable
  dplyr::filter(n_miss != 0) %>%         # On garde seulement les variables qui ont au moins une valeur manquante
 
  dplyr::rename("manquant" = "n_miss",   # On renomme les colonnes pour plus de lisibilité
                "pourcentage" = "pct_miss")
table_manquant1
```

```{r dbl2,results='hide'}
table_manquant2 <- Individus_dataset %>%
  naniar::miss_var_summary() %>%         # Résumé du nombre et pourcentage de valeurs manquantes par variable
  dplyr::filter(n_miss != 0) %>%         # On garde seulement les variables qui ont au moins une valeur manquante
 
  dplyr::rename("manquant" = "n_miss",   # On renomme les colonnes pour plus de lisibilité
                "pourcentage" = "pct_miss")
table_manquant2
```

```{r}
# Suppression des colonnes presque vides (seuil de 95%)

# Suppression des colonnes presque vides (seuil de 95%)
principal_dataset <- principal_dataset %>%
  select(where(~sum(is.na(.)) < 0.95 * nrow(principal_dataset)))

Individus_dataset <- Individus_dataset %>%
  select(where(~sum(is.na(.)) < 0.95 * nrow(Individus_dataset)))

# Suppression des lignes presque vides (seuil de 95%)
principal_dataset <- principal_dataset %>%
  filter(rowSums(is.na(.)) < 0.95 * ncol(.))

Individus_dataset <- Individus_dataset %>%
  filter(rowSums(is.na(.)) < 0.95 * ncol(.))
```

\newpage

# Analyse socio-economique des deplaces internes du Sudan en 2023

## 1) Pyramide des ages des individus

## **2) Caracteristiques du chef de menage**

```{r tbl}

# Appliquer le thème compact
set_gtsummary_theme(theme_gtsummary_compact())

# Convertir les colonnes "labelled" en facteurs et s'assurer que l'âge est numérique
library(forcats)

Individus_dataset <- Individus_dataset %>%
  filter(age_years, hh_02, hh_08) %>%
  mutate(
    intro_07_1 = haven::as_factor(intro_07_1),
    hh_02 = haven::as_factor(hh_02),
    hh_08 = haven::as_factor(hh_08),
    age_years = as.numeric(age_years)
  ) %>%
  filter(intro_07_1 %in% c("Refugees", "Host community North")) %>%  # ← Garde seulement ces 2 modalités
  mutate(intro_07_1 = fct_drop(intro_07_1))  # ← Supprime les autres niveaux inutiles

# Création du tableau sociodémographique
tableau_analyse_sociodemo <- Individus_dataset %>%
  tbl_summary(
    include = c(age_years, hh_02, hh_08),
    by = intro_07_1,
    statistic = list(
      all_continuous() ~ "{mean} ({sd})",
      all_categorical() ~ "{n} ({p}%)"
    ),
    label = list(
      hh_02 ~ "Sexe du chef de ménage",
      age_years ~ "Âge du chef de ménage",
      hh_08 ~ "Situation matrimoniale"
    ),
    missing = "no"
  ) %>%
  add_n() %>%
  modify_header(label = "**Variables socio-démographiques**") %>%
  bold_labels() %>%
  italicize_levels()

# Conversion en flextable
as_flex_table(tableau_analyse_sociodemo)
```

## **3) Crowding Index ou l’indice d’affluence**

# **Analyse de la securite alimentaire des deplaces internes**

## Score de consommation alimentaire (SCA)

### Faites une analyse descriptive des variables qui composent le SCA

```{r}
fcs_vars <- principal_dataset %>%
  dplyr::select("food_div1","food_div2","food_div3","food_div4","food_div5","food_div6","food_div7","food_div8")
```

Les variables concernées sont : `r colnames(fcs_vars)`.

```{r}
desc_var_sca <- principal_dataset %>%
  select(food_div1, food_div2, food_div3, food_div4, food_div5, food_div6, food_div7, food_div8) %>%
  tbl_summary(
    statistic = list(all_continuous() ~ "{mean} ({sd})\nmin: {min}, max: {max}\nP25: {p25}, P75: {p75}"),
    digits = all_continuous() ~ 2,
    label = list(
      food_div1 ~ "Céréales & tubercules (jours)",
      food_div2 ~ "Légumineuses/noix (jours)",
      food_div3 ~ "Légumes (jours)",
      food_div4 ~ "Fruits (jours)",
      food_div5 ~ "Viande/poisson/œufs (jours)",
      food_div6 ~ "Produits laitiers (jours)",
      food_div7 ~ "Sucre (jours)",
      food_div8 ~ "Matières grasses (jours)"
    ),
    missing = "no"
  ) %>%
  as_flex_table() %>%
  theme_zebra()

desc_var_sca
```

### Calculer le score de consommation alimentaire

```{r}
# Étape 1 : liste des variables d'alimentation
fcs_vars <- c("food_div1","food_div2","food_div3","food_div4",
              "food_div5","food_div6","food_div7","food_div8")

# Étape 2 : poids dans l'ordre correspondant
principal_dataset <- principal_dataset %>%
  mutate(
    # Calcul du score pondéré par groupe alimentaire avec food_div
    
    # food_div1 : Céréales & tubercules – poids 2
    food_div1_w = food_div1 * 2,

    # food_div2 : Légumineuses/noix – poids 3
    food_div2_w = food_div2 * 3,

    # food_div3 : Légumes – poids 1
    food_div3_w = food_div3 * 1,

    # food_div4 : Fruits – poids 1
    food_div4_w = food_div4 * 1,

    # food_div5 : Viande/poisson/œufs – poids 4
    food_div5_w = food_div5 * 4,

    # food_div6 : Produits laitiers – poids 4
    food_div6_w = food_div6 * 4,

    # food_div7 : Sucre – poids 0.5
    food_div7_w = food_div7 * 0.5,

    # food_div8 : Matières grasses – poids 0.5
    food_div8_w = food_div8 * 0.5,

    # Score total SCA
    SCA = food_div1_w + food_div2_w + food_div3_w + food_div4_w +food_div5_w + food_div6_w + food_div7_w + food_div8_w
  )
```

### Faites un tableau illustrant le poids attribue a chaque groupe alimentaire pour le calcul du SCA (la somme totale des poids doit etre egale a 16)

### Categoriser le SCA selon les seuil 21/35 et 28/42

```{r}
# Classification des ménages selon les seuils standards (21/35 et 28/42)
principal_dataset <- principal_dataset %>% 
  mutate(
    # Catégorisation avec le seuil 21/35
    fcs_cat_21_35 = case_when(
      SCA <= 21 ~ "Pauvre",
      SCA <= 35 ~ "Limite",
      TRUE ~ "Acceptable"
    ),
    fcs_cat_21_35 = factor(fcs_cat_21_35, levels = c("Pauvre", "Limite", "Acceptable")),
    
    # Catégorisation avec le seuil 28/42
    fcs_cat_28_42 = case_when(
      SCA <= 28 ~ "Pauvre",
      SCA <= 42 ~ "Limite",
      TRUE ~ "Acceptable"
    ),
    fcs_cat_28_42 = factor(fcs_cat_28_42, levels = c("Pauvre", "Limite", "Acceptable"))
  )
```

### Faites un tableau illustrant le poids attribue a chaque groupe alimentaire pour le calcul du SCA (la somme totale des poids doit etre egale a 16)

c.  Tableau illustrant les poids attribués

| Groupe alimentaire    | Exemples                  | Poids FCS |
|-----------------------|---------------------------|-----------|
| Céréales, tubercules  | Riz, pain, manioc, igname | 2         |
| Légumineuses          | Haricots, lentilles, pois | 3         |
| Produits laitiers     | Lait, yaourt, fromage     | 4         |
| Viandes/Poissons/Œufs | Viande, poisson, œufs     | 4         |
| Légumes               | Feuilles, gombo, carottes | 1         |
| Fruits                | Mangue, banane, orange    | 1         |
| Graisses/Huiles       | Huile, beurre, margarine  | 0.5       |
| Sucre                 | Sucre, miel, confiture    | 0.5       |
| Condiments            | Sel, épices, thé, café    | 0         |

### Categoriser le SCA selon les seuil 21/35 et 28/42

```{r}
# Classification des ménages selon les seuils standards (21/35 et 28/42)
principal_dataset <- principal_dataset %>% 
  mutate(
    # Catégorisation avec le seuil 21/35
    fcs_cat_21_35 = case_when(
      SCA <= 21 ~ "Pauvre",
      SCA <= 35 ~ "Limite",
      TRUE ~ "Acceptable"
    ),
    fcs_cat_21_35 = factor(fcs_cat_21_35, levels = c("Pauvre", "Limite", "Acceptable")),
    
    # Catégorisation avec le seuil 28/42
    fcs_cat_28_42 = case_when(
      SCA <= 28 ~ "Pauvre",
      SCA <= 42 ~ "Limite",
      TRUE ~ "Acceptable"
    ),
    fcs_cat_28_42 = factor(fcs_cat_28_42, levels = c("Pauvre", "Limite", "Acceptable"))
  )
```

c.  Tableau illustrant les poids attribués

| Groupe alimentaire    | Exemples                  | Poids FCS |
|-----------------------|---------------------------|-----------|
| Céréales, tubercules  | Riz, pain, manioc, igname | 2         |
| Légumineuses          | Haricots, lentilles, pois | 3         |
| Produits laitiers     | Lait, yaourt, fromage     | 4         |
| Viandes/Poissons/Œufs | Viande, poisson, œufs     | 4         |
| Légumes               | Feuilles, gombo, carottes | 1         |
| Fruits                | Mangue, banane, orange    | 1         |
| Graisses/Huiles       | Huile, beurre, margarine  | 0.5       |
| Sucre                 | Sucre, miel, confiture    | 0.5       |
| Condiments            | Sel, épices, thé, café    | 0         |


### Categoriser le SCA selon les seuil 21/35 et 28/42

```{r}
# Classification des ménages selon les seuils standards (21/35 et 28/42)
principal_dataset <- principal_dataset %>% 
  mutate(
    # Catégorisation avec le seuil 21/35
    fcs_cat_21_35 = case_when(
      SCA <= 21 ~ "Pauvre",
      SCA <= 35 ~ "Limite",
      TRUE ~ "Acceptable"
    ),
    fcs_cat_21_35 = factor(fcs_cat_21_35, levels = c("Pauvre", "Limite", "Acceptable")),
    
    # Catégorisation avec le seuil 28/42
    fcs_cat_28_42 = case_when(
      SCA <= 28 ~ "Pauvre",
      SCA <= 42 ~ "Limite",
      TRUE ~ "Acceptable"
    ),
    fcs_cat_28_42 = factor(fcs_cat_28_42, levels = c("Pauvre", "Limite", "Acceptable"))
  )
```

```{r}
tab_SCA <- principal_dataset %>% 
  gtsummary::tbl_summary(
    include = c(SCA, fcs_cat_28_42,fcs_cat_21_35 ),
     statistic = all_continuous() ~ "{mean} ({sd}, {min}, {max})"
  ) %>% 
  modify_caption("Score de consommation alimentaire")

tab_SCA
```

# L’indice réduit des stratégies de survie (rCSI):

\newpage

# Table des matières

<!---BLOCK_TOC--->

\newpage

###### Conclusion

Merci pour votre attention
